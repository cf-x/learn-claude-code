[
  {
    "version": "s01",
    "locale": "ja",
    "title": "s01: The Agent Loop",
    "content": "# s01: The Agent Loop\n\n> AIコーディングエージェントの秘密はすべて、モデルが「終了」と判断するまでツール結果をモデルにフィードバックし続けるwhileループにある。\n\n## 問題\n\nなぜ言語モデルは単体でコーディングの質問に答えられないのか。それはコーディングが「現実世界とのインタラクション」を必要とするからだ。モデルはファイルを読み、テストを実行し、エラーを確認し、反復する必要がある。一回のプロンプト-レスポンスのやり取りではこれは実現できない。\n\nagent loopがなければ、ユーザーが自分でモデルの出力をコピーペーストして戻す必要がある。つまりユーザー自身がループの役割を果たすことになる。agent loopはこれを自動化する: モデルを呼び出し、モデルが要求したツールを実行し、結果をフィードバックし、モデルが「完了」と言うまで繰り返す。\n\n単純なタスクを考えてみよう: 「helloと出力するPythonファイルを作成せよ」。モデルは(1)ファイルを書くことを決定し、(2)書き、(3)動作を検証する必要がある。最低でも3回のツール呼び出しが必要だ。ループがなければ、そのたびに手動の介入が必要になる。\n\n## 解決策\n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> |  Tool   |\n|  prompt  |      |       |      | execute |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                      (loop continues)\n\nThe loop terminates when stop_reason != \"tool_use\".\nThat single condition is the entire control flow.\n```\n\n## 仕組み\n\n1. ユーザーがプロンプトを入力する。これが最初のメッセージになる。\n\n```python\nhistory.append({\"role\": \"user\", \"content\": query})\n```\n\n2. メッセージ配列がツール定義と共にLLMに送信される。\n\n```python\nresponse = client.messages.create(\n    model=MODEL, system=SYSTEM, messages=messages,\n    tools=TOOLS, max_tokens=8000,\n)\n```\n\n3. アシスタントのレスポンスがメッセージに追加される。\n\n```python\nmessages.append({\"role\": \"assistant\", \"content\": response.content})\n```\n\n4. stop reasonを確認する。モデルがツールを呼び出さなかった場合、ループは終了する。これが唯一の終了条件だ。\n\n```python\nif response.stop_reason != \"tool_use\":\n    return\n```\n\n5. レスポンス中の各tool_useブロックについて、ツール(このセッションではbash)を実行し、結果を収集する。\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        output = run_bash(block.input[\"command\"])\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n6. 結果がuserメッセージとして追加され、ループが続行する。\n\n```python\nmessages.append({\"role\": \"user\", \"content\": results})\n```\n\n## 主要コード\n\n最小限のエージェント -- パターン全体が30行未満\n(`agents/s01_agent_loop.py` 66-86行目):\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                output = run_bash(block.input[\"command\"])\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## 変更点\n\nこれはセッション1 -- 出発点である。前のセッションは存在しない。\n\n| Component     | Before     | After                          |\n|---------------|------------|--------------------------------|\n| Agent loop    | (none)     | `while True` + stop_reason     |\n| Tools         | (none)     | `bash` (one tool)              |\n| Messages      | (none)     | Accumulating list              |\n| Control flow  | (none)     | `stop_reason != \"tool_use\"`    |\n\n## 本番環境との対応\n\n実際のClaude Codeでも、同じループがメインREPLの中で動いている。コアとなるループロジックは`agent.ts`にあり、同一のパターンに従う: メッセージをAPIに送り、`stop_reason`を確認し、ツールを実行し、結果を追加する。本番バージョンではエラーハンドリング、トークンカウント、ストリーミング、リトライロジックが追加されているが、根本的な構造は変わらない。すべてのClaude Codeセッションはこのwhileループである。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s01_agent_loop.py\n```\n\n試せるプロンプト例:\n\n1. `Create a file called hello.py that prints \"Hello, World!\"`\n2. `List all Python files in this directory`\n3. `What is the current git branch?`\n4. `Create a directory called test_output and write 3 files in it`\n"
  },
  {
    "version": "s01",
    "locale": "zh",
    "title": "s01: Agent Loop (智能体循环)",
    "content": "# s01: Agent Loop (智能体循环)\n\n> AI 编程智能体的全部秘密就是一个 while 循环 -- 把工具执行结果反馈给模型, 直到模型决定停止。\n\n## 问题\n\n为什么语言模型不能直接回答编程问题? 因为编程需要**与真实世界交互**。模型需要读取文件、运行测试、检查错误、反复迭代。单次的提示-响应交互无法做到这些。\n\n没有 agent loop, 你就得手动把输出复制粘贴回模型。用户自己变成了那个循环。Agent loop 将这个过程自动化: 调用模型, 执行它要求的工具, 把结果送回去, 重复 -- 直到模型说 \"我完成了\"。\n\n考虑一个简单任务: \"创建一个打印 hello 的 Python 文件。\" 模型需要 (1) 决定写文件, (2) 写入文件, (3) 验证是否正常工作。至少三次工具调用。没有循环的话, 每一次都需要人工干预。\n\n## 解决方案\n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> |  Tool   |\n|  prompt  |      |       |      | execute |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                      (loop continues)\n\nThe loop terminates when stop_reason != \"tool_use\".\nThat single condition is the entire control flow.\n```\n\n## 工作原理\n\n1. 用户提供一个 prompt, 成为第一条消息。\n\n```python\nhistory.append({\"role\": \"user\", \"content\": query})\n```\n\n2. 消息数组连同工具定义一起发送给 LLM。\n\n```python\nresponse = client.messages.create(\n    model=MODEL, system=SYSTEM, messages=messages,\n    tools=TOOLS, max_tokens=8000,\n)\n```\n\n3. 助手的响应被追加到消息列表中。\n\n```python\nmessages.append({\"role\": \"assistant\", \"content\": response.content})\n```\n\n4. 检查 stop_reason。如果模型没有调用工具, 循环结束。这是唯一的退出条件。\n\n```python\nif response.stop_reason != \"tool_use\":\n    return\n```\n\n5. 对响应中的每个 tool_use 块, 执行工具 (本节课中是 bash) 并收集结果。\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        output = run_bash(block.input[\"command\"])\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n6. 结果作为 user 消息追加, 循环继续。\n\n```python\nmessages.append({\"role\": \"user\", \"content\": results})\n```\n\n## 核心代码\n\n最小可行智能体 -- 不到 30 行代码实现整个模式\n(来自 `agents/s01_agent_loop.py`, 第 66-86 行):\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                output = run_bash(block.input[\"command\"])\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## 变更内容\n\n这是第 1 节课 -- 起点。没有前置课程。\n\n| 组件          | 之前       | 之后                           |\n|---------------|------------|--------------------------------|\n| Agent loop    | (无)       | `while True` + stop_reason     |\n| Tools         | (无)       | `bash` (单一工具)              |\n| Messages      | (无)       | 累积式消息列表                 |\n| Control flow  | (无)       | `stop_reason != \"tool_use\"`    |\n\n## 生产环境参考\n\n在真实的 Claude Code 中, 同样的循环运行在主 REPL 内。核心循环逻辑位于 `agent.ts`, 遵循完全相同的模式: 发送消息到 API, 检查 `stop_reason`, 执行工具, 追加结果。生产版本增加了错误处理、token 计数、流式输出和重试逻辑, 但基本结构没有变化。每一个 Claude Code 会话本质上都是这个 while 循环。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s01_agent_loop.py\n```\n\n可以尝试的提示:\n\n1. `Create a file called hello.py that prints \"Hello, World!\"`\n2. `List all Python files in this directory`\n3. `What is the current git branch?`\n4. `Create a directory called test_output and write 3 files in it`\n"
  },
  {
    "version": "s01",
    "locale": "en",
    "title": "s01: The Agent Loop",
    "content": "# s01: The Agent Loop\n\n> The entire secret of AI coding agents is a while loop that feeds tool results back to the model until the model decides to stop.\n\n## The Problem\n\nWhy can't a language model just answer a coding question? Because coding\nrequires _interaction with the real world_. The model needs to read files,\nrun tests, check errors, and iterate. A single prompt-response pair cannot\ndo this.\n\nWithout the agent loop, you would have to copy-paste outputs back into the\nmodel yourself. The user becomes the loop. The agent loop automates this:\ncall the model, execute whatever tools it asks for, feed the results back,\nrepeat until the model says \"I'm done.\"\n\nConsider a simple task: \"Create a Python file that prints hello.\" The model\nneeds to (1) decide to write a file, (2) write it, (3) verify it works.\nThat is three tool calls minimum. Without a loop, each one requires manual\nhuman intervention.\n\n## The Solution\n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> |  Tool   |\n|  prompt  |      |       |      | execute |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                      (loop continues)\n\nThe loop terminates when stop_reason != \"tool_use\".\nThat single condition is the entire control flow.\n```\n\n## How It Works\n\n1. The user provides a prompt. It becomes the first message.\n\n```python\nhistory.append({\"role\": \"user\", \"content\": query})\n```\n\n2. The messages array is sent to the LLM along with the tool definitions.\n\n```python\nresponse = client.messages.create(\n    model=MODEL, system=SYSTEM, messages=messages,\n    tools=TOOLS, max_tokens=8000,\n)\n```\n\n3. The assistant response is appended to messages.\n\n```python\nmessages.append({\"role\": \"assistant\", \"content\": response.content})\n```\n\n4. We check the stop reason. If the model did not call a tool, the loop\n   ends. This is the only exit condition.\n\n```python\nif response.stop_reason != \"tool_use\":\n    return\n```\n\n5. For each tool_use block in the response, execute the tool (bash in this\n   session) and collect results.\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        output = run_bash(block.input[\"command\"])\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n6. The results are appended as a user message, and the loop continues.\n\n```python\nmessages.append({\"role\": \"user\", \"content\": results})\n```\n\n## Key Code\n\nThe minimum viable agent -- the entire pattern in under 30 lines\n(from `agents/s01_agent_loop.py`, lines 66-86):\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                output = run_bash(block.input[\"command\"])\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## What Changed\n\nThis is session 1 -- the starting point. There is no prior session.\n\n| Component     | Before     | After                          |\n|---------------|------------|--------------------------------|\n| Agent loop    | (none)     | `while True` + stop_reason     |\n| Tools         | (none)     | `bash` (one tool)              |\n| Messages      | (none)     | Accumulating list              |\n| Control flow  | (none)     | `stop_reason != \"tool_use\"`    |\n\n## Production Reference\n\nIn real Claude Code, this same loop runs inside the main REPL. The core\nloop logic lives in `agent.ts` and follows the identical pattern: send\nmessages to the API, check `stop_reason`, execute tools, append results.\nThe production version adds error handling, token counting, streaming,\nand retry logic, but the fundamental structure is unchanged. Every Claude\nCode session is this while loop.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s01_agent_loop.py\n```\n\nExample prompts to try:\n\n1. `Create a file called hello.py that prints \"Hello, World!\"`\n2. `List all Python files in this directory`\n3. `What is the current git branch?`\n4. `Create a directory called test_output and write 3 files in it`\n"
  },
  {
    "version": "s02",
    "locale": "ja",
    "title": "s02: Tools",
    "content": "# s02: Tools\n\n> ディスパッチマップがツール呼び出しをハンドラ関数にルーティングする -- ループ自体はまったく変更しない。\n\n## 問題\n\n`bash`だけでは、エージェントはすべてをシェル経由で行う: ファイルの読み取り、書き込み、編集。これは動くが脆弱だ。`cat`の出力は予期しないタイミングで切り詰められる。`sed`による置換は特殊文字で失敗する。直接的な関数呼び出しの方がシンプルなのに、モデルはシェルパイプラインの構築にトークンを浪費する。\n\nさらに重要なのは、bashがセキュリティ上の攻撃面であること。bashの呼び出しはシェルでできることなら何でもできてしまう。`read_file`や`write_file`のような専用ツールがあれば、モデルが危険な操作を避けることを期待するのではなく、ツールレベルでパスのサンドボックス化や危険なパターンのブロックを強制できる。\n\n重要な洞察は、ツールを追加してもループを変更する必要がないということだ。s01のループはそのまま同一で維持される。ツール配列にエントリを追加し、ハンドラ関数を追加し、ディスパッチマップで接続するだけだ。\n\n## 解決策\n\n```\n+----------+      +-------+      +------------------+\n|   User   | ---> |  LLM  | ---> | Tool Dispatch    |\n|  prompt  |      |       |      | {                |\n+----------+      +---+---+      |   bash: run_bash |\n                      ^          |   read: run_read |\n                      |          |   write: run_wr  |\n                      +----------+   edit: run_edit |\n                      tool_result| }                |\n                                 +------------------+\n\nThe dispatch map is a dict: {tool_name: handler_function}\nOne lookup replaces any if/elif chain.\n```\n\n## 仕組み\n\n1. 各ツールのハンドラ関数を定義する。各関数はツールのinput_schemaに対応するキーワード引数を受け取り、文字列の結果を返す。\n\n```python\ndef run_read(path: str, limit: int = None) -> str:\n    text = safe_path(path).read_text()\n    lines = text.splitlines()\n    if limit and limit < len(lines):\n        lines = lines[:limit]\n    return \"\\n\".join(lines)[:50000]\n```\n\n2. ツール名とハンドラを結びつけるディスパッチマップを作成する。\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n```\n\n3. agent loop内で、ハードコードの代わりに名前でハンドラをルックアップする。\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        handler = TOOL_HANDLERS.get(block.name)\n        output = handler(**block.input)\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n4. パスのサンドボックス化により、モデルがワークスペースの外に出ることを防ぐ。\n\n```python\ndef safe_path(p: str) -> Path:\n    path = (WORKDIR / p).resolve()\n    if not path.is_relative_to(WORKDIR):\n        raise ValueError(f\"Path escapes workspace: {p}\")\n    return path\n```\n\n## 主要コード\n\nディスパッチパターン(`agents/s02_multi_tool.py` 93-129行目):\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input) if handler \\\n                    else f\"Unknown tool: {block.name}\"\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## s01からの変更点\n\n| Component      | Before (s01)       | After (s02)                |\n|----------------|--------------------|----------------------------|\n| Tools          | 1 (bash only)      | 4 (bash, read, write, edit)|\n| Dispatch       | Hardcoded bash call | `TOOL_HANDLERS` dict       |\n| Path safety    | None               | `safe_path()` sandbox      |\n| Agent loop     | Unchanged          | Unchanged                  |\n\n## 本番環境との対応\n\nClaude Codeも同じディスパッチマップパターンを使用している。ツールはツールレジストリに登録され、メインループは名前でハンドラをルックアップする。本番のツールセットはより大きく(Bash, Read, Write, Edit, Glob, Grep, WebFetchなど)、しかし各ツールは同じ契約に従う: スキーマに合致する入力を受け取り、文字列の結果を返す。Claude Codeに新しいツールを追加するには、ハンドラ関数とスキーマエントリを追加するだけでよい -- ループは変更しない。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s02_multi_tool.py\n```\n\n試せるプロンプト例:\n\n1. `Read the file requirements.txt`\n2. `Create a file called greet.py with a greet(name) function`\n3. `Edit greet.py to add a docstring to the function`\n4. `Read greet.py to verify the edit worked`\n5. `Run the greet function with bash: python -c \"from greet import greet; greet('World')\"`\n"
  },
  {
    "version": "s02",
    "locale": "zh",
    "title": "s02: Tools (工具)",
    "content": "# s02: Tools (工具)\n\n> 一个分发映射表 (dispatch map) 将工具调用路由到处理函数 -- 循环本身完全不需要改动。\n\n## 问题\n\n只有 `bash` 时, 智能体所有操作都通过 shell: 读文件、写文件、编辑文件。这能用但很脆弱。`cat` 的输出会被不可预测地截断。`sed` 替换遇到特殊字符就会失败。模型浪费大量 token 构造 shell 管道, 而一个直接的函数调用会简单得多。\n\n更重要的是, bash 是一个安全攻击面。每次 bash 调用都能做 shell 能做的一切。有了专用工具如 `read_file` 和 `write_file`, 你可以在工具层面强制路径沙箱化, 阻止危险模式, 而不是寄希望于模型自觉回避。\n\n关键洞察: 添加工具不需要修改循环。s01 的循环保持不变。你只需在工具数组中添加条目, 编写处理函数, 然后通过 dispatch map 把它们关联起来。\n\n## 解决方案\n\n```\n+----------+      +-------+      +------------------+\n|   User   | ---> |  LLM  | ---> | Tool Dispatch    |\n|  prompt  |      |       |      | {                |\n+----------+      +---+---+      |   bash: run_bash |\n                      ^          |   read: run_read |\n                      |          |   write: run_wr  |\n                      +----------+   edit: run_edit |\n                      tool_result| }                |\n                                 +------------------+\n\nThe dispatch map is a dict: {tool_name: handler_function}\nOne lookup replaces any if/elif chain.\n```\n\n## 工作原理\n\n1. 为每个工具定义处理函数。每个函数接受与工具 input_schema 对应的关键字参数, 返回字符串结果。\n\n```python\ndef run_read(path: str, limit: int = None) -> str:\n    text = safe_path(path).read_text()\n    lines = text.splitlines()\n    if limit and limit < len(lines):\n        lines = lines[:limit]\n    return \"\\n\".join(lines)[:50000]\n```\n\n2. 创建 dispatch map, 将工具名映射到处理函数。\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n```\n\n3. 在 agent loop 中, 按名称查找处理函数, 而不是硬编码。\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        handler = TOOL_HANDLERS.get(block.name)\n        output = handler(**block.input)\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n4. 路径沙箱化防止模型逃逸出工作区。\n\n```python\ndef safe_path(p: str) -> Path:\n    path = (WORKDIR / p).resolve()\n    if not path.is_relative_to(WORKDIR):\n        raise ValueError(f\"Path escapes workspace: {p}\")\n    return path\n```\n\n## 核心代码\n\ndispatch 模式 (来自 `agents/s02_multi_tool.py`, 第 93-129 行):\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input) if handler \\\n                    else f\"Unknown tool: {block.name}\"\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## 相对 s01 的变更\n\n| 组件           | 之前 (s01)         | 之后 (s02)                     |\n|----------------|--------------------|----------------------------|\n| Tools          | 1 (仅 bash)        | 4 (bash, read, write, edit)|\n| Dispatch       | 硬编码 bash 调用   | `TOOL_HANDLERS` 字典       |\n| 路径安全       | 无                 | `safe_path()` 沙箱         |\n| Agent loop     | 不变               | 不变                       |\n\n## 生产环境参考\n\nClaude Code 使用相同的 dispatch map 模式。工具注册在工具注册表中, 主循环按名称查找处理函数。生产工具集要大得多 (Bash, Read, Write, Edit, Glob, Grep, WebFetch 等), 但每个工具遵循相同的契约: 接受符合 schema 的输入, 返回字符串结果。给 Claude Code 添加新工具意味着添加一个处理函数和一个 schema 条目 -- 循环不需要改动。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s02_multi_tool.py\n```\n\n可以尝试的提示:\n\n1. `Read the file requirements.txt`\n2. `Create a file called greet.py with a greet(name) function`\n3. `Edit greet.py to add a docstring to the function`\n4. `Read greet.py to verify the edit worked`\n5. `Run the greet function with bash: python -c \"from greet import greet; greet('World')\"`\n"
  },
  {
    "version": "s02",
    "locale": "en",
    "title": "s02: Tools",
    "content": "# s02: Tools\n\n> A dispatch map routes tool calls to handler functions -- the loop itself does not change at all.\n\n## The Problem\n\nWith only `bash`, the agent shells out for everything: reading files,\nwriting files, editing files. This works but is fragile. `cat` output\ngets truncated unpredictably. `sed` replacements fail on special\ncharacters. The model wastes tokens constructing shell pipelines when\na direct function call would be simpler.\n\nMore importantly, bash is a security surface. Every bash call can do\nanything the shell can do. With dedicated tools like `read_file` and\n`write_file`, you can enforce path sandboxing and block dangerous\npatterns at the tool level rather than hoping the model avoids them.\n\nThe insight is that adding tools does not require changing the loop.\nThe loop from s01 stays identical. You add entries to the tools array,\nadd handler functions, and wire them together with a dispatch map.\n\n## The Solution\n\n```\n+----------+      +-------+      +------------------+\n|   User   | ---> |  LLM  | ---> | Tool Dispatch    |\n|  prompt  |      |       |      | {                |\n+----------+      +---+---+      |   bash: run_bash |\n                      ^          |   read: run_read |\n                      |          |   write: run_wr  |\n                      +----------+   edit: run_edit |\n                      tool_result| }                |\n                                 +------------------+\n\nThe dispatch map is a dict: {tool_name: handler_function}\nOne lookup replaces any if/elif chain.\n```\n\n## How It Works\n\n1. Define handler functions for each tool. Each takes keyword arguments\n   matching the tool's input_schema and returns a string result.\n\n```python\ndef run_read(path: str, limit: int = None) -> str:\n    text = safe_path(path).read_text()\n    lines = text.splitlines()\n    if limit and limit < len(lines):\n        lines = lines[:limit]\n    return \"\\n\".join(lines)[:50000]\n```\n\n2. Create the dispatch map linking tool names to handlers.\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n```\n\n3. In the agent loop, look up the handler by name instead of hardcoding.\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        handler = TOOL_HANDLERS.get(block.name)\n        output = handler(**block.input)\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n4. Path sandboxing prevents the model from escaping the workspace.\n\n```python\ndef safe_path(p: str) -> Path:\n    path = (WORKDIR / p).resolve()\n    if not path.is_relative_to(WORKDIR):\n        raise ValueError(f\"Path escapes workspace: {p}\")\n    return path\n```\n\n## Key Code\n\nThe dispatch pattern (from `agents/s02_multi_tool.py`, lines 93-129):\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input) if handler \\\n                    else f\"Unknown tool: {block.name}\"\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## What Changed From s01\n\n| Component      | Before (s01)       | After (s02)                |\n|----------------|--------------------|----------------------------|\n| Tools          | 1 (bash only)      | 4 (bash, read, write, edit)|\n| Dispatch       | Hardcoded bash call | `TOOL_HANDLERS` dict       |\n| Path safety    | None               | `safe_path()` sandbox      |\n| Agent loop     | Unchanged          | Unchanged                  |\n\n## Production Reference\n\nClaude Code uses the same dispatch map pattern. Tools are registered in a\ntool registry, and the main loop does a lookup by name to find the handler.\nThe production tool set is much larger (Bash, Read, Write, Edit, Glob,\nGrep, WebFetch, etc.), but each one follows the same contract: take input\nmatching the schema, return a string result. Adding a new tool to Claude\nCode means adding a handler function and a schema entry -- the loop does\nnot change.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s02_multi_tool.py\n```\n\nExample prompts to try:\n\n1. `Read the file requirements.txt`\n2. `Create a file called greet.py with a greet(name) function`\n3. `Edit greet.py to add a docstring to the function`\n4. `Read greet.py to verify the edit worked`\n5. `Run the greet function with bash: python -c \"from greet import greet; greet('World')\"`\n"
  },
  {
    "version": "s03",
    "locale": "ja",
    "title": "s03: TodoWrite",
    "content": "# s03: TodoWrite\n\n> TodoManagerによりエージェントが自身の進捗を追跡でき、nagリマインダーの注入により更新を忘れた場合に強制的に更新させる。\n\n## 問題\n\nエージェントがマルチステップのタスクに取り組むとき、何を完了し何が残っているかを見失うことが多い。明示的な計画がなければ、モデルは作業を繰り返したり、ステップを飛ばしたり、脱線したりする可能性がある。ユーザーにはエージェントの内部計画が見えない。\n\nこれは見た目以上に深刻だ。長い会話ではモデルが「ドリフト」する -- コンテキストウィンドウがツール結果で埋まるにつれ、システムプロンプトの影響力が薄れていく。10ステップのリファクタリングタスクでステップ1-3を完了した後、モデルはステップ4-10の存在を忘れて即興で行動し始めるかもしれない。\n\n解決策は構造化された状態管理だ: モデルが明示的に書き込むTodoManager。モデルは計画を作成し、作業中のアイテムをin_progressとしてマークし、完了時にcompletedとマークする。nagリマインダーは、モデルが3ラウンド以上todoを更新しなかった場合にナッジを注入する。\n\n教育上の簡略化: nagの閾値3ラウンドは教育目的の可視化のために低く設定されている。本番のClaude Codeでは過剰なプロンプトを避けるため閾値は約10に設定されている。\n\n## 解決策\n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> | Tools   |\n|  prompt  |      |       |      | + todo  |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                            |\n                +-----------+-----------+\n                | TodoManager state     |\n                | [ ] task A            |\n                | [>] task B  <- doing  |\n                | [x] task C            |\n                +-----------------------+\n                            |\n                if rounds_since_todo >= 3:\n                  inject <reminder> into tool_result\n```\n\n## 仕組み\n\n1. TodoManagerはアイテムのリストをバリデーションして保持する。`in_progress`にできるのは一度に1つだけ。\n\n```python\nclass TodoManager:\n    def __init__(self):\n        self.items = []\n\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one task can be in_progress\")\n        self.items = validated\n        return self.render()\n```\n\n2. `todo`ツールは他のツールと同様にディスパッチマップに追加される。\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":  lambda **kw: run_bash(kw[\"command\"]),\n    # ...other tools...\n    \"todo\":  lambda **kw: TODO.update(kw[\"items\"]),\n}\n```\n\n3. nagリマインダーは、モデルが3ラウンド以上`todo`を呼び出さなかった場合にtool_resultメッセージに`<reminder>`タグを注入する。\n\n```python\ndef agent_loop(messages: list):\n    rounds_since_todo = 0\n    while True:\n        if rounds_since_todo >= 3 and messages:\n            last = messages[-1]\n            if (last[\"role\"] == \"user\"\n                    and isinstance(last.get(\"content\"), list)):\n                last[\"content\"].insert(0, {\n                    \"type\": \"text\",\n                    \"text\": \"<reminder>Update your todos.</reminder>\",\n                })\n        # ... rest of loop ...\n        rounds_since_todo = 0 if used_todo else rounds_since_todo + 1\n```\n\n4. システムプロンプトがモデルにtodoによる計画を指示する。\n\n```python\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nUse the todo tool to plan multi-step tasks.\nMark in_progress before starting, completed when done.\nPrefer tools over prose.\"\"\"\n```\n\n## 主要コード\n\nTodoManagerとnag注入(`agents/s03_structured_planning.py` 51-85行目および158-187行目):\n\n```python\nclass TodoManager:\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one in_progress\")\n        self.items = validated\n        return self.render()\n\n# In agent_loop:\nif rounds_since_todo >= 3:\n    last[\"content\"].insert(0, {\n        \"type\": \"text\",\n        \"text\": \"<reminder>Update your todos.</reminder>\",\n    })\n```\n\n## s02からの変更点\n\n| Component      | Before (s02)     | After (s03)              |\n|----------------|------------------|--------------------------|\n| Tools          | 4                | 5 (+todo)                |\n| Planning       | None             | TodoManager with statuses|\n| Nag injection  | None             | `<reminder>` after 3 rounds|\n| Agent loop     | Simple dispatch  | + rounds_since_todo counter|\n\n## 本番環境との対応\n\nClaude Codeも同じパターンをTodoWriteツールとTodoReadツールで実装している。モデルはステータス(pending, in_progress, completed)付きの構造化されたtodoリストを作成する。nagリマインダーの概念は「system reminders」として現れる -- モデルがドリフトしたときに軌道修正するために注入されるメッセージだ。本番のTodoManagerは優先度やセッション間の永続化をサポートしている。「一度にin_progressは1つだけ」という制約は逐次的な集中を強制し、モデルが頻繁にコンテキストスイッチするのを防ぐ。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s03_structured_planning.py\n```\n\n試せるプロンプト例:\n\n1. `Refactor the file hello.py: add type hints, docstrings, and a main guard`\n2. `Create a Python package with __init__.py, utils.py, and tests/test_utils.py`\n3. `Review all Python files and fix any style issues`\n"
  },
  {
    "version": "s03",
    "locale": "zh",
    "title": "s03: TodoWrite (待办写入)",
    "content": "# s03: TodoWrite (待办写入)\n\n> TodoManager 让智能体能追踪自己的进度, 而 nag reminder 注入机制在它忘记更新时强制提醒。\n\n## 问题\n\n当智能体处理多步骤任务时, 它经常丢失对已完成和待办事项的追踪。没有显式的计划, 模型可能重复工作、跳过步骤或跑偏。用户也无法看到智能体内部的计划。\n\n这个问题比听起来更严重。长对话会导致模型 \"漂移\" -- 随着上下文窗口被工具结果填满, 系统提示的影响力逐渐减弱。一个 10 步的重构任务可能完成了 1-3 步, 然后模型就开始即兴发挥, 因为它忘了第 4-10 步的存在。\n\n解决方案是结构化状态: 一个模型显式写入的 TodoManager。模型创建计划, 工作时将项目标记为 in_progress, 完成后标记为 completed。nag reminder 机制在模型连续 3 轮以上不更新待办时注入提醒。\n\n教学简化说明: 这里 nag 阈值设为 3 轮是为了教学可见性。生产环境的 Claude Code 使用约 10 轮的阈值以避免过度提醒。\n\n## 解决方案\n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> | Tools   |\n|  prompt  |      |       |      | + todo  |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                            |\n                +-----------+-----------+\n                | TodoManager state     |\n                | [ ] task A            |\n                | [>] task B  <- doing  |\n                | [x] task C            |\n                +-----------------------+\n                            |\n                if rounds_since_todo >= 3:\n                  inject <reminder> into tool_result\n```\n\n## 工作原理\n\n1. TodoManager 验证并存储一组带状态的项目。同一时间只允许一个项目处于 `in_progress` 状态。\n\n```python\nclass TodoManager:\n    def __init__(self):\n        self.items = []\n\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one task can be in_progress\")\n        self.items = validated\n        return self.render()\n```\n\n2. `todo` 工具和其他工具一样添加到 dispatch map 中。\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":  lambda **kw: run_bash(kw[\"command\"]),\n    # ...other tools...\n    \"todo\":  lambda **kw: TODO.update(kw[\"items\"]),\n}\n```\n\n3. nag reminder 在模型连续 3 轮以上不调用 `todo` 时, 向 tool_result 消息中注入 `<reminder>` 标签。\n\n```python\ndef agent_loop(messages: list):\n    rounds_since_todo = 0\n    while True:\n        if rounds_since_todo >= 3 and messages:\n            last = messages[-1]\n            if (last[\"role\"] == \"user\"\n                    and isinstance(last.get(\"content\"), list)):\n                last[\"content\"].insert(0, {\n                    \"type\": \"text\",\n                    \"text\": \"<reminder>Update your todos.</reminder>\",\n                })\n        # ... rest of loop ...\n        rounds_since_todo = 0 if used_todo else rounds_since_todo + 1\n```\n\n4. 系统提示指导模型使用 todo 进行规划。\n\n```python\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nUse the todo tool to plan multi-step tasks.\nMark in_progress before starting, completed when done.\nPrefer tools over prose.\"\"\"\n```\n\n## 核心代码\n\nTodoManager 和 nag 注入 (来自 `agents/s03_structured_planning.py`,\n第 51-85 行和第 158-187 行):\n\n```python\nclass TodoManager:\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one in_progress\")\n        self.items = validated\n        return self.render()\n\n# In agent_loop:\nif rounds_since_todo >= 3:\n    last[\"content\"].insert(0, {\n        \"type\": \"text\",\n        \"text\": \"<reminder>Update your todos.</reminder>\",\n    })\n```\n\n## 相对 s02 的变更\n\n| 组件           | 之前 (s02)       | 之后 (s03)                   |\n|----------------|------------------|--------------------------|\n| Tools          | 4                | 5 (+todo)                |\n| 规划           | 无               | 带状态的 TodoManager     |\n| Nag 注入       | 无               | 3 轮后注入 `<reminder>`  |\n| Agent loop     | 简单分发         | + rounds_since_todo 计数器|\n\n## 生产环境参考\n\nClaude Code 通过 TodoWrite 和 TodoRead 工具实现了同样的模式。模型创建带状态 (pending, in_progress, completed) 的结构化待办列表。nag reminder 概念在生产中表现为 \"系统提醒\" (system reminders) -- 当模型偏离方向时注入的引导消息。生产版 TodoManager 支持优先级和跨会话持久化。\"同一时间只允许一个 in_progress\" 的约束强制顺序聚焦, 防止模型过快地切换上下文。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s03_structured_planning.py\n```\n\n可以尝试的提示:\n\n1. `Refactor the file hello.py: add type hints, docstrings, and a main guard`\n2. `Create a Python package with __init__.py, utils.py, and tests/test_utils.py`\n3. `Review all Python files and fix any style issues`\n"
  },
  {
    "version": "s03",
    "locale": "en",
    "title": "s03: TodoWrite",
    "content": "# s03: TodoWrite\n\n> A TodoManager lets the agent track its own progress, and a nag reminder injection forces it to keep updating when it forgets.\n\n## The Problem\n\nWhen an agent works on a multi-step task, it often loses track of what it\nhas done and what remains. Without explicit planning, the model might repeat\nwork, skip steps, or wander off on tangents. The user has no visibility\ninto the agent's internal plan.\n\nThis is worse than it sounds. Long conversations cause the model to \"drift\"\n-- the system prompt fades in influence as the context window fills with\ntool results. A 10-step refactoring task might complete steps 1-3, then\nthe model starts improvising because it forgot steps 4-10 existed.\n\nThe solution is structured state: a TodoManager that the model writes to\nexplicitly. The model creates a plan, marks items in_progress as it works,\nand marks them completed when done. A nag reminder injects a nudge if the\nmodel goes 3+ rounds without updating its todos.\n\nTeaching simplification: the nag threshold of 3 rounds is set low for\nteaching visibility. Production Claude Code uses a threshold around 10\nto avoid over-prompting.\n\n## The Solution\n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> | Tools   |\n|  prompt  |      |       |      | + todo  |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                            |\n                +-----------+-----------+\n                | TodoManager state     |\n                | [ ] task A            |\n                | [>] task B  <- doing  |\n                | [x] task C            |\n                +-----------------------+\n                            |\n                if rounds_since_todo >= 3:\n                  inject <reminder> into tool_result\n```\n\n## How It Works\n\n1. The TodoManager validates and stores a list of items with statuses.\n   Only one item can be `in_progress` at a time.\n\n```python\nclass TodoManager:\n    def __init__(self):\n        self.items = []\n\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one task can be in_progress\")\n        self.items = validated\n        return self.render()\n```\n\n2. The `todo` tool is added to the dispatch map like any other tool.\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":  lambda **kw: run_bash(kw[\"command\"]),\n    # ...other tools...\n    \"todo\":  lambda **kw: TODO.update(kw[\"items\"]),\n}\n```\n\n3. The nag reminder injects a `<reminder>` tag into the tool_result\n   messages when the model goes 3+ rounds without calling `todo`.\n\n```python\ndef agent_loop(messages: list):\n    rounds_since_todo = 0\n    while True:\n        if rounds_since_todo >= 3 and messages:\n            last = messages[-1]\n            if (last[\"role\"] == \"user\"\n                    and isinstance(last.get(\"content\"), list)):\n                last[\"content\"].insert(0, {\n                    \"type\": \"text\",\n                    \"text\": \"<reminder>Update your todos.</reminder>\",\n                })\n        # ... rest of loop ...\n        rounds_since_todo = 0 if used_todo else rounds_since_todo + 1\n```\n\n4. The system prompt instructs the model to use todos for planning.\n\n```python\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nUse the todo tool to plan multi-step tasks.\nMark in_progress before starting, completed when done.\nPrefer tools over prose.\"\"\"\n```\n\n## Key Code\n\nThe TodoManager and nag injection (from `agents/s03_structured_planning.py`,\nlines 51-85 and 158-187):\n\n```python\nclass TodoManager:\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one in_progress\")\n        self.items = validated\n        return self.render()\n\n# In agent_loop:\nif rounds_since_todo >= 3:\n    last[\"content\"].insert(0, {\n        \"type\": \"text\",\n        \"text\": \"<reminder>Update your todos.</reminder>\",\n    })\n```\n\n## What Changed From s02\n\n| Component      | Before (s02)     | After (s03)              |\n|----------------|------------------|--------------------------|\n| Tools          | 4                | 5 (+todo)                |\n| Planning       | None             | TodoManager with statuses|\n| Nag injection  | None             | `<reminder>` after 3 rounds|\n| Agent loop     | Simple dispatch  | + rounds_since_todo counter|\n\n## Production Reference\n\nClaude Code implements the same pattern through TodoWrite and TodoRead\ntools. The model creates structured todo lists with statuses (pending,\nin_progress, completed). The nag reminder concept appears as \"system\nreminders\" -- injected messages that steer the model back on track when\nit drifts. The production TodoManager supports priorities and persistence\nacross sessions. The constraint of \"one in_progress at a time\" forces\nsequential focus, preventing the model from context-switching too rapidly.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s03_structured_planning.py\n```\n\nExample prompts to try:\n\n1. `Refactor the file hello.py: add type hints, docstrings, and a main guard`\n2. `Create a Python package with __init__.py, utils.py, and tests/test_utils.py`\n3. `Review all Python files and fix any style issues`\n"
  },
  {
    "version": "s04",
    "locale": "ja",
    "title": "s04: Subagents",
    "content": "# s04: Subagents\n\n> サブエージェントは新しいメッセージリストで実行され、親とファイルシステムを共有し、要約のみを返す -- 親のコンテキストをクリーンに保つ。\n\n## 問題\n\nエージェントが作業するにつれ、メッセージ配列は膨張する。すべてのツール呼び出し、ファイル読み取り、bash出力が蓄積されていく。20-30回のツール呼び出しの後、コンテキストウィンドウは無関係な履歴で溢れる。ちょっとした質問に答えるために500行のファイルを読むと、永久に500行がコンテキストに追加される。\n\nこれは探索的タスクで特に深刻だ。「このプロジェクトはどのテストフレームワークを使っているか」という質問には5つのファイルを読む必要があるかもしれないが、親エージェントには5つのファイルの内容すべては不要だ -- 「pytest with conftest.py configuration」という回答だけが必要なのだ。\n\n解決策はプロセスの分離だ: `messages=[]`で子エージェントを生成する。子は探索し、ファイルを読み、コマンドを実行する。終了時には最終的なテキストレスポンスだけが親に返される。子のメッセージ履歴全体は破棄される。\n\n## 解決策\n\n```\nParent agent                     Subagent\n+------------------+             +------------------+\n| messages=[...]   |             | messages=[]      | <-- fresh\n|                  |  dispatch   |                  |\n| tool: task       | ---------->| while tool_use:  |\n|   prompt=\"...\"   |            |   call tools     |\n|                  |  summary   |   append results |\n|   result = \"...\" | <--------- | return last text |\n+------------------+             +------------------+\n          |\nParent context stays clean.\nSubagent context is discarded.\n```\n\n## 仕組み\n\n1. 親エージェントにサブエージェント生成をトリガーする`task`ツールが追加される。子は`task`を除くすべての基本ツールを取得する(再帰的な生成は不可)。\n\n```python\nPARENT_TOOLS = CHILD_TOOLS + [\n    {\"name\": \"task\",\n     \"description\": \"Spawn a subagent with fresh context.\",\n     \"input_schema\": {\n         \"type\": \"object\",\n         \"properties\": {\n             \"prompt\": {\"type\": \"string\"},\n             \"description\": {\"type\": \"string\"},\n         },\n         \"required\": [\"prompt\"],\n     }},\n]\n```\n\n2. サブエージェントは委譲されたプロンプトのみを含む新しいメッセージリストで開始する。ファイルシステムは共有される。\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):  # safety limit\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\n            \"role\": \"assistant\", \"content\": response.content\n        })\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n```\n\n3. 最終テキストのみが親に返される。子の30回以上のツール呼び出し履歴は破棄される。\n\n```python\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n4. 親はこの要約を通常のtool_resultとして受け取る。\n\n```python\nif block.name == \"task\":\n    output = run_subagent(block.input[\"prompt\"])\nresults.append({\n    \"type\": \"tool_result\",\n    \"tool_use_id\": block.id,\n    \"content\": str(output),\n})\n```\n\n## 主要コード\n\nサブエージェント関数(`agents/s04_context_isolation.py` 110-128行目):\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\"role\": \"assistant\",\n                             \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input)\n                results.append({\"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": str(output)[:50000]})\n        sub_messages.append({\"role\": \"user\", \"content\": results})\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n## s03からの変更点\n\n| Component      | Before (s03)     | After (s04)               |\n|----------------|------------------|---------------------------|\n| Tools          | 5                | 5 (base) + task (parent)  |\n| Context        | Single shared    | Parent + child isolation  |\n| Subagent       | None             | `run_subagent()` function |\n| Return value   | N/A              | Summary text only         |\n| Todo system    | TodoManager      | Removed (not needed here) |\n\n## 本番環境との対応\n\nClaude Codeではこれを`spawn()`付きのTaskツールとして実装している。モデルがTaskを呼び出すと、`messages=[]`で子プロセスが作成される。子はファイルシステムとツール定義を引き継ぐが、独自のコンテキストウィンドウを持つ。Claude Codeではサブエージェントの説明文がサポートされており、親のUIに表示されるため、親コンテキストを汚すことなく子が何をしているか確認できる。本番バージョンではサブエージェントの深さ制限(TaskからTaskの再帰は不可)と最大反復回数の制限も行っている。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s04_context_isolation.py\n```\n\n試せるプロンプト例:\n\n1. `Use a subtask to find what testing framework this project uses`\n2. `Delegate: read all .py files and summarize what each one does`\n3. `Use a task to create a new module, then verify it from here`\n"
  },
  {
    "version": "s04",
    "locale": "zh",
    "title": "s04: Subagent (子智能体)",
    "content": "# s04: Subagent (子智能体)\n\n> 子智能体使用全新的消息列表运行, 与父智能体共享文件系统, 仅返回摘要 -- 保持父上下文的整洁。\n\n## 问题\n\n随着智能体工作, 它的消息数组不断增长。每次工具调用、每次文件读取、每次 bash 输出都在累积。20-30 次工具调用后, 上下文窗口充满了无关的历史。为了回答一个简单问题而读取的 500 行文件, 会永久占据上下文中的 500 行空间。\n\n这对探索性任务尤其糟糕。\"这个项目用了什么测试框架?\" 可能需要读取 5 个文件, 但父智能体的历史中并不需要这 5 个文件的全部内容 -- 它只需要答案: \"pytest, 使用 conftest.py 配置。\"\n\n解决方案是进程隔离: 以 `messages=[]` 启动一个子智能体。子智能体进行探索、读取文件、运行命令。完成后, 只有最终的文本响应返回给父智能体。子智能体的全部消息历史被丢弃。\n\n## 解决方案\n\n```\nParent agent                     Subagent\n+------------------+             +------------------+\n| messages=[...]   |             | messages=[]      | <-- fresh\n|                  |  dispatch   |                  |\n| tool: task       | ---------->| while tool_use:  |\n|   prompt=\"...\"   |            |   call tools     |\n|                  |  summary   |   append results |\n|   result = \"...\" | <--------- | return last text |\n+------------------+             +------------------+\n          |\nParent context stays clean.\nSubagent context is discarded.\n```\n\n## 工作原理\n\n1. 父智能体拥有一个 `task` 工具用于触发子智能体的生成。子智能体获得除 `task` 外的所有基础工具 (不允许递归生成)。\n\n```python\nPARENT_TOOLS = CHILD_TOOLS + [\n    {\"name\": \"task\",\n     \"description\": \"Spawn a subagent with fresh context.\",\n     \"input_schema\": {\n         \"type\": \"object\",\n         \"properties\": {\n             \"prompt\": {\"type\": \"string\"},\n             \"description\": {\"type\": \"string\"},\n         },\n         \"required\": [\"prompt\"],\n     }},\n]\n```\n\n2. 子智能体以全新的消息列表启动, 仅包含委派的 prompt。它共享相同的文件系统。\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):  # safety limit\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\n            \"role\": \"assistant\", \"content\": response.content\n        })\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n```\n\n3. 只有最终文本返回给父智能体。子智能体 30+ 次工具调用的历史被丢弃。\n\n```python\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n4. 父智能体将此摘要作为普通的 tool_result 接收。\n\n```python\nif block.name == \"task\":\n    output = run_subagent(block.input[\"prompt\"])\nresults.append({\n    \"type\": \"tool_result\",\n    \"tool_use_id\": block.id,\n    \"content\": str(output),\n})\n```\n\n## 核心代码\n\n子智能体函数 (来自 `agents/s04_context_isolation.py`, 第 110-128 行):\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\"role\": \"assistant\",\n                             \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input)\n                results.append({\"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": str(output)[:50000]})\n        sub_messages.append({\"role\": \"user\", \"content\": results})\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n## 相对 s03 的变更\n\n| 组件           | 之前 (s03)       | 之后 (s04)                    |\n|----------------|------------------|---------------------------|\n| Tools          | 5                | 5 (基础) + task (仅父端)  |\n| 上下文         | 单一共享         | 父 + 子隔离               |\n| Subagent       | 无               | `run_subagent()` 函数     |\n| 返回值         | 不适用           | 仅摘要文本                |\n| Todo 系统      | TodoManager      | 已移除 (非本节重点)       |\n\n## 生产环境参考\n\nClaude Code 通过 Task 工具和 `spawn()` 实现了这一机制。当模型调用 Task 时, 会创建一个 `messages=[]` 的子进程。子进程继承文件系统和工具定义, 但拥有自己的上下文窗口。Claude Code 还支持子智能体描述, 显示在父端的 UI 中, 让用户能看到子智能体在做什么而不会污染父上下文。生产版本还限制了子智能体深度 (不允许从 Task 中递归调用 Task) 并强制执行最大迭代次数限制。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s04_context_isolation.py\n```\n\n可以尝试的提示:\n\n1. `Use a subtask to find what testing framework this project uses`\n2. `Delegate: read all .py files and summarize what each one does`\n3. `Use a task to create a new module, then verify it from here`\n"
  },
  {
    "version": "s04",
    "locale": "en",
    "title": "s04: Subagents",
    "content": "# s04: Subagents\n\n> A subagent runs with a fresh messages list, shares the filesystem with the parent, and returns only a summary -- keeping the parent context clean.\n\n## The Problem\n\nAs the agent works, its messages array grows. Every tool call, every file\nread, every bash output accumulates. After 20-30 tool calls, the context\nwindow is crowded with irrelevant history. Reading a 500-line file to\nanswer a quick question permanently adds 500 lines to the context.\n\nThis is particularly bad for exploratory tasks. \"What testing framework\ndoes this project use?\" might require reading 5 files, but the parent\nagent does not need all 5 file contents in its history -- it just needs\nthe answer: \"pytest with conftest.py configuration.\"\n\nThe solution is process isolation: spawn a child agent with `messages=[]`.\nThe child explores, reads files, runs commands. When it finishes, only its\nfinal text response returns to the parent. The child's entire message\nhistory is discarded.\n\n## The Solution\n\n```\nParent agent                     Subagent\n+------------------+             +------------------+\n| messages=[...]   |             | messages=[]      | <-- fresh\n|                  |  dispatch   |                  |\n| tool: task       | ---------->| while tool_use:  |\n|   prompt=\"...\"   |            |   call tools     |\n|                  |  summary   |   append results |\n|   result = \"...\" | <--------- | return last text |\n+------------------+             +------------------+\n          |\nParent context stays clean.\nSubagent context is discarded.\n```\n\n## How It Works\n\n1. The parent agent gets a `task` tool that triggers subagent spawning.\n   The child gets all base tools except `task` (no recursive spawning).\n\n```python\nPARENT_TOOLS = CHILD_TOOLS + [\n    {\"name\": \"task\",\n     \"description\": \"Spawn a subagent with fresh context.\",\n     \"input_schema\": {\n         \"type\": \"object\",\n         \"properties\": {\n             \"prompt\": {\"type\": \"string\"},\n             \"description\": {\"type\": \"string\"},\n         },\n         \"required\": [\"prompt\"],\n     }},\n]\n```\n\n2. The subagent starts with a fresh messages list containing only\n   the delegated prompt. It shares the same filesystem.\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):  # safety limit\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\n            \"role\": \"assistant\", \"content\": response.content\n        })\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n```\n\n3. Only the final text returns to the parent. The child's 30+ tool\n   call history is discarded.\n\n```python\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n4. The parent receives this summary as a normal tool_result.\n\n```python\nif block.name == \"task\":\n    output = run_subagent(block.input[\"prompt\"])\nresults.append({\n    \"type\": \"tool_result\",\n    \"tool_use_id\": block.id,\n    \"content\": str(output),\n})\n```\n\n## Key Code\n\nThe subagent function (from `agents/s04_context_isolation.py`,\nlines 110-128):\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\"role\": \"assistant\",\n                             \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input)\n                results.append({\"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": str(output)[:50000]})\n        sub_messages.append({\"role\": \"user\", \"content\": results})\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n## What Changed From s03\n\n| Component      | Before (s03)     | After (s04)               |\n|----------------|------------------|---------------------------|\n| Tools          | 5                | 5 (base) + task (parent)  |\n| Context        | Single shared    | Parent + child isolation  |\n| Subagent       | None             | `run_subagent()` function |\n| Return value   | N/A              | Summary text only         |\n| Todo system    | TodoManager      | Removed (not needed here) |\n\n## Production Reference\n\nClaude Code implements this as the Task tool with `spawn()`. When the\nmodel calls Task, a child process is created with `messages=[]`. The\nchild inherits the filesystem and tool definitions but gets its own\ncontext window. Claude Code also supports subagent descriptions that\nappear in the parent's UI, so users can see what the child is doing\nwithout polluting the parent context. The production version also limits\nsubagent depth (no recursive Task-from-Task) and enforces a max\niteration count.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s04_context_isolation.py\n```\n\nExample prompts to try:\n\n1. `Use a subtask to find what testing framework this project uses`\n2. `Delegate: read all .py files and summarize what each one does`\n3. `Use a task to create a new module, then verify it from here`\n"
  },
  {
    "version": "s05",
    "locale": "ja",
    "title": "s05: Skills",
    "content": "# s05: Skills\n\n> 2層のスキル注入により、スキル名をシステムプロンプトに(低コスト)、スキル本体をtool_resultに(オンデマンド)配置することで、システムプロンプトの肥大化を回避する。\n\n## 問題\n\nエージェントに特定のドメインのワークフローを遵守させたい: gitの規約、テストパターン、コードレビューのチェックリストなど。単純なアプローチはすべてをシステムプロンプトに入れることだ。しかしシステムプロンプトの実効的な注意力は有限であり、テキストが多すぎるとモデルはその一部を無視し始める。\n\n10個のスキルが各2000トークンあれば、20,000トークンのシステムプロンプトになる。モデルは先頭と末尾に注意を払い、中間部分は飛ばし読みする。さらに悪いことに、ほとんどのスキルは任意のタスクに対して無関係だ。ファイル編集のタスクにgitワークフローの指示は不要だ。\n\n2層アプローチがこれを解決する: 第1層はシステムプロンプトにスキルの短い説明を置く(スキルあたり約100トークン)。第2層はモデルが`load_skill`を呼び出した時だけ、スキル本体の全文をtool_resultに読み込む。モデルはどのスキルが存在するかを知り(低コスト)、必要な時だけ読み込む(関連する時のみ)。\n\n## 解決策\n\n```\nSystem prompt (Layer 1 -- always present):\n+--------------------------------------+\n| You are a coding agent.              |\n| Skills available:                    |\n|   - git: Git workflow helpers        |  ~100 tokens/skill\n|   - test: Testing best practices     |\n+--------------------------------------+\n\nWhen model calls load_skill(\"git\"):\n+--------------------------------------+\n| tool_result (Layer 2 -- on demand):  |\n| <skill name=\"git\">                   |\n|   Full git workflow instructions...  |  ~2000 tokens\n|   Step 1: ...                        |\n|   Step 2: ...                        |\n| </skill>                             |\n+--------------------------------------+\n```\n\n## 仕組み\n\n1. スキルファイルは`.skills/`にYAMLフロントマター付きMarkdownとして配置される。\n\n```\n.skills/\n  git.md       # ---\\n description: Git workflow\\n ---\\n ...\n  test.md      # ---\\n description: Testing patterns\\n ---\\n ...\n```\n\n2. SkillLoaderがフロントマターを解析し、メタデータと本体を分離する。\n\n```python\nclass SkillLoader:\n    def _parse_frontmatter(self, text: str) -> tuple:\n        match = re.match(\n            r\"^---\\n(.*?)\\n---\\n(.*)\", text, re.DOTALL\n        )\n        if not match:\n            return {}, text\n        meta = {}\n        for line in match.group(1).strip().splitlines():\n            if \":\" in line:\n                key, val = line.split(\":\", 1)\n                meta[key.strip()] = val.strip()\n        return meta, match.group(2).strip()\n```\n\n3. 第1層: `get_descriptions()`がシステムプロンプト用の短い行を返す。\n\n```python\ndef get_descriptions(self) -> str:\n    lines = []\n    for name, skill in self.skills.items():\n        desc = skill[\"meta\"].get(\"description\", \"No description\")\n        lines.append(f\"  - {name}: {desc}\")\n    return \"\\n\".join(lines)\n\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nSkills available:\n{SKILL_LOADER.get_descriptions()}\"\"\"\n```\n\n4. 第2層: `get_content()`が`<skill>`タグで囲まれた本体全文を返す。\n\n```python\ndef get_content(self, name: str) -> str:\n    skill = self.skills.get(name)\n    if not skill:\n        return f\"Error: Unknown skill '{name}'.\"\n    return f\"<skill name=\\\"{name}\\\">\\n{skill['body']}\\n</skill>\"\n```\n\n5. `load_skill`ツールはディスパッチマップの単なる一エントリだ。\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"load_skill\": lambda **kw: SKILL_LOADER.get_content(kw[\"name\"]),\n}\n```\n\n## 主要コード\n\nSkillLoaderクラス(`agents/s05_knowledge_loading.py` 51-97行目):\n\n```python\nclass SkillLoader:\n    def __init__(self, skills_dir: Path):\n        self.skills = {}\n        for f in sorted(skills_dir.glob(\"*.md\")):\n            text = f.read_text()\n            meta, body = self._parse_frontmatter(text)\n            self.skills[f.stem] = {\n                \"meta\": meta, \"body\": body\n            }\n\n    def get_descriptions(self) -> str:\n        lines = []\n        for name, skill in self.skills.items():\n            desc = skill[\"meta\"].get(\"description\", \"\")\n            lines.append(f\"  - {name}: {desc}\")\n        return \"\\n\".join(lines)\n\n    def get_content(self, name: str) -> str:\n        skill = self.skills.get(name)\n        if not skill:\n            return f\"Error: Unknown skill '{name}'.\"\n        return (f\"<skill name=\\\"{name}\\\">\\n\"\n                f\"{skill['body']}\\n</skill>\")\n```\n\n## s04からの変更点\n\n| Component      | Before (s04)     | After (s05)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5 (base + task)  | 5 (base + load_skill)      |\n| System prompt  | Static string    | + skill descriptions       |\n| Knowledge      | None             | .skills/*.md files         |\n| Injection      | None             | Two-layer (system + result)|\n| Subagent       | `run_subagent()` | Removed (different focus)  |\n\n## 本番環境との対応\n\nClaude CodeではこれをSkillツールとして実装している。スキルはスキルディレクトリ内のSKILL.mdファイルとして保存される。システムプロンプトには利用可能なスキルのコンパクトなリストが含まれる。モデルが`Skill(\"skill-name\")`を呼び出すと、SKILL.mdの全内容がtool_resultに注入される。このパターンはCLAUDE.mdプロジェクト指示にも使われている -- システムプロンプトを肥大化させるのではなく、オンデマンドでコンテキストに読み込まれる。2層アプローチにより、モデルの注意力を劣化させることなく数十のスキルにスケールできる。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s05_knowledge_loading.py\n```\n\n試せるプロンプト例:\n\n1. `What skills are available?`\n2. `Load the agent-builder skill and follow its instructions`\n3. `I need to do a code review -- load the relevant skill first`\n4. `Build an MCP server using the mcp-builder skill`\n"
  },
  {
    "version": "s05",
    "locale": "zh",
    "title": "s05: Skills (技能加载)",
    "content": "# s05: Skills (技能加载)\n\n> 两层技能注入避免了系统提示膨胀: 在系统提示中放技能名称 (低成本), 在 tool_result 中按需放入完整技能内容。\n\n## 问题\n\n你希望智能体针对不同领域遵循特定的工作流: git 约定、测试模式、代码审查清单。简单粗暴的做法是把所有内容都塞进系统提示。但系统提示的有效注意力是有限的 -- 文本太多, 模型就会开始忽略其中一部分。\n\n如果你有 10 个技能, 每个 2000 token, 那就是 20,000 token 的系统提示。模型关注开头和结尾, 但会略过中间部分。更糟糕的是, 这些技能中大部分与当前任务无关。文件编辑任务不需要 git 工作流说明。\n\n两层方案解决了这个问题: 第一层在系统提示中放入简短的技能描述 (每个技能约 100 token)。第二层只在模型调用 `load_skill` 时, 才将完整的技能内容加载到 tool_result 中。模型知道有哪些技能可用 (低成本), 按需加载它们 (只在相关时)。\n\n## 解决方案\n\n```\nSystem prompt (Layer 1 -- always present):\n+--------------------------------------+\n| You are a coding agent.              |\n| Skills available:                    |\n|   - git: Git workflow helpers        |  ~100 tokens/skill\n|   - test: Testing best practices     |\n+--------------------------------------+\n\nWhen model calls load_skill(\"git\"):\n+--------------------------------------+\n| tool_result (Layer 2 -- on demand):  |\n| <skill name=\"git\">                   |\n|   Full git workflow instructions...  |  ~2000 tokens\n|   Step 1: ...                        |\n|   Step 2: ...                        |\n| </skill>                             |\n+--------------------------------------+\n```\n\n## 工作原理\n\n1. 技能文件以 Markdown 格式存放在 `.skills/` 目录中, 带有 YAML frontmatter。\n\n```\n.skills/\n  git.md       # ---\\n description: Git workflow\\n ---\\n ...\n  test.md      # ---\\n description: Testing patterns\\n ---\\n ...\n```\n\n2. SkillLoader 解析 frontmatter, 分离元数据和正文。\n\n```python\nclass SkillLoader:\n    def _parse_frontmatter(self, text: str) -> tuple:\n        match = re.match(\n            r\"^---\\n(.*?)\\n---\\n(.*)\", text, re.DOTALL\n        )\n        if not match:\n            return {}, text\n        meta = {}\n        for line in match.group(1).strip().splitlines():\n            if \":\" in line:\n                key, val = line.split(\":\", 1)\n                meta[key.strip()] = val.strip()\n        return meta, match.group(2).strip()\n```\n\n3. 第一层: `get_descriptions()` 返回简短描述, 用于系统提示。\n\n```python\ndef get_descriptions(self) -> str:\n    lines = []\n    for name, skill in self.skills.items():\n        desc = skill[\"meta\"].get(\"description\", \"No description\")\n        lines.append(f\"  - {name}: {desc}\")\n    return \"\\n\".join(lines)\n\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nSkills available:\n{SKILL_LOADER.get_descriptions()}\"\"\"\n```\n\n4. 第二层: `get_content()` 返回用 `<skill>` 标签包裹的完整正文。\n\n```python\ndef get_content(self, name: str) -> str:\n    skill = self.skills.get(name)\n    if not skill:\n        return f\"Error: Unknown skill '{name}'.\"\n    return f\"<skill name=\\\"{name}\\\">\\n{skill['body']}\\n</skill>\"\n```\n\n5. `load_skill` 工具只是 dispatch map 中的又一个条目。\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"load_skill\": lambda **kw: SKILL_LOADER.get_content(kw[\"name\"]),\n}\n```\n\n## 核心代码\n\nSkillLoader 类 (来自 `agents/s05_knowledge_loading.py`, 第 51-97 行):\n\n```python\nclass SkillLoader:\n    def __init__(self, skills_dir: Path):\n        self.skills = {}\n        for f in sorted(skills_dir.glob(\"*.md\")):\n            text = f.read_text()\n            meta, body = self._parse_frontmatter(text)\n            self.skills[f.stem] = {\n                \"meta\": meta, \"body\": body\n            }\n\n    def get_descriptions(self) -> str:\n        lines = []\n        for name, skill in self.skills.items():\n            desc = skill[\"meta\"].get(\"description\", \"\")\n            lines.append(f\"  - {name}: {desc}\")\n        return \"\\n\".join(lines)\n\n    def get_content(self, name: str) -> str:\n        skill = self.skills.get(name)\n        if not skill:\n            return f\"Error: Unknown skill '{name}'.\"\n        return (f\"<skill name=\\\"{name}\\\">\\n\"\n                f\"{skill['body']}\\n</skill>\")\n```\n\n## 相对 s04 的变更\n\n| 组件           | 之前 (s04)       | 之后 (s05)                     |\n|----------------|------------------|----------------------------|\n| Tools          | 5 (基础 + task)  | 5 (基础 + load_skill)      |\n| 系统提示       | 静态字符串       | + 技能描述列表             |\n| 知识库         | 无               | .skills/*.md 文件          |\n| 注入方式       | 无               | 两层 (系统提示 + result)   |\n| Subagent       | `run_subagent()` | 已移除 (非本节重点)        |\n\n## 生产环境参考\n\nClaude Code 通过 Skill 工具实现了这一机制。技能以 SKILL.md 文件存储在技能目录中。系统提示包含一个紧凑的可用技能列表。当模型调用 `Skill(\"skill-name\")` 时, 完整的 SKILL.md 内容被注入到 tool_result 中。这种模式也用于 CLAUDE.md 项目指令 -- 它们按需加载到上下文中, 而不是让系统提示膨胀。两层方案可以扩展到数十个技能而不会降低模型的注意力质量。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s05_knowledge_loading.py\n```\n\n可以尝试的提示:\n\n1. `What skills are available?`\n2. `Load the agent-builder skill and follow its instructions`\n3. `I need to do a code review -- load the relevant skill first`\n4. `Build an MCP server using the mcp-builder skill`\n"
  },
  {
    "version": "s05",
    "locale": "en",
    "title": "s05: Skills",
    "content": "# s05: Skills\n\n> Two-layer skill injection avoids system prompt bloat by putting skill names in the system prompt (cheap) and full skill bodies in tool_result (on demand).\n\n## The Problem\n\nYou want the agent to follow specific workflows for different domains:\ngit conventions, testing patterns, code review checklists. The naive\napproach is to put everything in the system prompt. But the system prompt\nhas limited effective attention -- too much text and the model starts\nignoring parts of it.\n\nIf you have 10 skills at 2000 tokens each, that is 20,000 tokens of system\nprompt. The model pays attention to the beginning and end but skims the\nmiddle. Worse, most of those skills are irrelevant to any given task. A\nfile editing task does not need the git workflow instructions.\n\nThe two-layer approach solves this: Layer 1 puts short skill descriptions\nin the system prompt (~100 tokens per skill). Layer 2 loads the full skill\nbody into a tool_result only when the model calls `load_skill`. The model\nlearns what skills exist (cheap) and loads them on demand (only when\nrelevant).\n\n## The Solution\n\n```\nSystem prompt (Layer 1 -- always present):\n+--------------------------------------+\n| You are a coding agent.              |\n| Skills available:                    |\n|   - git: Git workflow helpers        |  ~100 tokens/skill\n|   - test: Testing best practices     |\n+--------------------------------------+\n\nWhen model calls load_skill(\"git\"):\n+--------------------------------------+\n| tool_result (Layer 2 -- on demand):  |\n| <skill name=\"git\">                   |\n|   Full git workflow instructions...  |  ~2000 tokens\n|   Step 1: ...                        |\n|   Step 2: ...                        |\n| </skill>                             |\n+--------------------------------------+\n```\n\n## How It Works\n\n1. Skill files live in `.skills/` as Markdown with YAML frontmatter.\n\n```\n.skills/\n  git.md       # ---\\n description: Git workflow\\n ---\\n ...\n  test.md      # ---\\n description: Testing patterns\\n ---\\n ...\n```\n\n2. The SkillLoader parses frontmatter and separates metadata from body.\n\n```python\nclass SkillLoader:\n    def _parse_frontmatter(self, text: str) -> tuple:\n        match = re.match(\n            r\"^---\\n(.*?)\\n---\\n(.*)\", text, re.DOTALL\n        )\n        if not match:\n            return {}, text\n        meta = {}\n        for line in match.group(1).strip().splitlines():\n            if \":\" in line:\n                key, val = line.split(\":\", 1)\n                meta[key.strip()] = val.strip()\n        return meta, match.group(2).strip()\n```\n\n3. Layer 1: `get_descriptions()` returns short lines for the system prompt.\n\n```python\ndef get_descriptions(self) -> str:\n    lines = []\n    for name, skill in self.skills.items():\n        desc = skill[\"meta\"].get(\"description\", \"No description\")\n        lines.append(f\"  - {name}: {desc}\")\n    return \"\\n\".join(lines)\n\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nSkills available:\n{SKILL_LOADER.get_descriptions()}\"\"\"\n```\n\n4. Layer 2: `get_content()` returns the full body wrapped in `<skill>` tags.\n\n```python\ndef get_content(self, name: str) -> str:\n    skill = self.skills.get(name)\n    if not skill:\n        return f\"Error: Unknown skill '{name}'.\"\n    return f\"<skill name=\\\"{name}\\\">\\n{skill['body']}\\n</skill>\"\n```\n\n5. The `load_skill` tool is just another entry in the dispatch map.\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"load_skill\": lambda **kw: SKILL_LOADER.get_content(kw[\"name\"]),\n}\n```\n\n## Key Code\n\nThe SkillLoader class (from `agents/s05_knowledge_loading.py`,\nlines 51-97):\n\n```python\nclass SkillLoader:\n    def __init__(self, skills_dir: Path):\n        self.skills = {}\n        for f in sorted(skills_dir.glob(\"*.md\")):\n            text = f.read_text()\n            meta, body = self._parse_frontmatter(text)\n            self.skills[f.stem] = {\n                \"meta\": meta, \"body\": body\n            }\n\n    def get_descriptions(self) -> str:\n        lines = []\n        for name, skill in self.skills.items():\n            desc = skill[\"meta\"].get(\"description\", \"\")\n            lines.append(f\"  - {name}: {desc}\")\n        return \"\\n\".join(lines)\n\n    def get_content(self, name: str) -> str:\n        skill = self.skills.get(name)\n        if not skill:\n            return f\"Error: Unknown skill '{name}'.\"\n        return (f\"<skill name=\\\"{name}\\\">\\n\"\n                f\"{skill['body']}\\n</skill>\")\n```\n\n## What Changed From s04\n\n| Component      | Before (s04)     | After (s05)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5 (base + task)  | 5 (base + load_skill)      |\n| System prompt  | Static string    | + skill descriptions       |\n| Knowledge      | None             | .skills/*.md files         |\n| Injection      | None             | Two-layer (system + result)|\n| Subagent       | `run_subagent()` | Removed (different focus)  |\n\n## Production Reference\n\nClaude Code implements this as the Skill tool. Skills are stored as\nSKILL.md files in skill directories. The system prompt includes a compact\nlist of available skills. When the model calls `Skill(\"skill-name\")`,\nthe full SKILL.md content is injected into the tool_result. This pattern\nis also used for CLAUDE.md project instructions -- they are loaded into\nthe context on demand rather than bloating the system prompt. The two-layer\napproach scales to dozens of skills without degrading model attention.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s05_knowledge_loading.py\n```\n\nExample prompts to try:\n\n1. `What skills are available?`\n2. `Load the agent-builder skill and follow its instructions`\n3. `I need to do a code review -- load the relevant skill first`\n4. `Build an MCP server using the mcp-builder skill`\n"
  },
  {
    "version": "s06",
    "locale": "ja",
    "title": "s06: Compact",
    "content": "# s06: Compact\n\n> 3層の圧縮パイプラインにより、古いツール結果の戦略的な忘却、トークンが閾値を超えた時の自動要約、オンデマンドの手動圧縮を組み合わせて、エージェントを無期限に動作可能にする。\n\n## 問題\n\nコンテキストウィンドウは有限だ。十分なツール呼び出しの後、メッセージ配列がモデルのコンテキスト上限を超え、API呼び出しが失敗する。ハード制限に達する前でも、パフォーマンスは劣化する: モデルは遅くなり、精度が落ち、以前のメッセージを無視し始める。\n\n200,000トークンのコンテキストウィンドウは大きく聞こえるが、1000行のソースファイルに対する一回の`read_file`で約4000トークンを消費する。30ファイルを読み20回のbashコマンドを実行すると、100,000トークン以上になる。何らかの圧縮がなければ、エージェントは大規模なコードベースで作業できない。\n\n3層のパイプラインは積極性を段階的に上げて対処する:\n第1層(micro-compact)は毎ターン静かに古いツール結果を置換する。\n第2層(auto-compact)はトークンが閾値を超えた時に完全な要約を発動する。\n第3層(manual compact)はモデル自身が圧縮をトリガーできる。\n\n教育上の簡略化: ここでのトークン推定は大まかな「文字数/4」ヒューリスティックを使用している。本番システムでは正確なカウントのために適切なトークナイザーライブラリを使用する。\n\n## 解決策\n\n```\nEvery turn:\n+------------------+\n| Tool call result |\n+------------------+\n        |\n        v\n[Layer 1: micro_compact]        (silent, every turn)\n  Replace tool_result > 3 turns old\n  with \"[Previous: used {tool_name}]\"\n        |\n        v\n[Check: tokens > 50000?]\n   |               |\n   no              yes\n   |               |\n   v               v\ncontinue    [Layer 2: auto_compact]\n              Save transcript to .transcripts/\n              LLM summarizes conversation.\n              Replace all messages with [summary].\n                    |\n                    v\n            [Layer 3: compact tool]\n              Model calls compact explicitly.\n              Same summarization as auto_compact.\n```\n\n## 仕組み\n\n1. **第1層 -- micro_compact**: 各LLM呼び出しの前に、直近3件以前のすべてのtool_resultエントリを見つけて内容を置換する。\n\n```python\ndef micro_compact(messages: list) -> list:\n    tool_results = []\n    for i, msg in enumerate(messages):\n        if msg[\"role\"] == \"user\" and isinstance(msg.get(\"content\"), list):\n            for j, part in enumerate(msg[\"content\"]):\n                if isinstance(part, dict) and part.get(\"type\") == \"tool_result\":\n                    tool_results.append((i, j, part))\n    if len(tool_results) <= KEEP_RECENT:\n        return messages\n    to_clear = tool_results[:-KEEP_RECENT]\n    for _, _, part in to_clear:\n        if len(part.get(\"content\", \"\")) > 100:\n            tool_id = part.get(\"tool_use_id\", \"\")\n            tool_name = tool_name_map.get(tool_id, \"unknown\")\n            part[\"content\"] = f\"[Previous: used {tool_name}]\"\n    return messages\n```\n\n2. **第2層 -- auto_compact**: 推定トークン数が50,000を超えた時、完全なトランスクリプトを保存し、LLMに要約を依頼する。\n\n```python\ndef auto_compact(messages: list) -> list:\n    TRANSCRIPT_DIR.mkdir(exist_ok=True)\n    transcript_path = TRANSCRIPT_DIR / f\"transcript_{int(time.time())}.jsonl\"\n    with open(transcript_path, \"w\") as f:\n        for msg in messages:\n            f.write(json.dumps(msg, default=str) + \"\\n\")\n    response = client.messages.create(\n        model=MODEL,\n        messages=[{\"role\": \"user\", \"content\":\n            \"Summarize this conversation for continuity...\"\n            + json.dumps(messages, default=str)[:80000]}],\n        max_tokens=2000,\n    )\n    summary = response.content[0].text\n    return [\n        {\"role\": \"user\", \"content\": f\"[Compressed]\\n\\n{summary}\"},\n        {\"role\": \"assistant\", \"content\": \"Understood. Continuing.\"},\n    ]\n```\n\n3. **第3層 -- manual compact**: `compact`ツールが同じ要約処理をオンデマンドでトリガーする。\n\n```python\nif manual_compact:\n    messages[:] = auto_compact(messages)\n```\n\n4. agent loopが3つの層すべてを統合する。\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        micro_compact(messages)\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)\n        response = client.messages.create(...)\n        # ... tool execution ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)\n```\n\n## 主要コード\n\n3層パイプライン(`agents/s06_compression.py` 67-93行目および189-223行目):\n\n```python\nTHRESHOLD = 50000\nKEEP_RECENT = 3\n\ndef micro_compact(messages):\n    # Replace old tool results with placeholders\n    ...\n\ndef auto_compact(messages):\n    # Save transcript, LLM summarize, replace messages\n    ...\n\ndef agent_loop(messages):\n    while True:\n        micro_compact(messages)          # Layer 1\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)  # Layer 2\n        response = client.messages.create(...)\n        # ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)  # Layer 3\n```\n\n## s05からの変更点\n\n| Component      | Before (s05)     | After (s06)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5                | 5 (base + compact)         |\n| Context mgmt   | None             | Three-layer compression    |\n| Micro-compact  | None             | Old results -> placeholders|\n| Auto-compact   | None             | Token threshold trigger    |\n| Manual compact | None             | `compact` tool             |\n| Transcripts    | None             | Saved to .transcripts/     |\n| Skills         | load_skill       | Removed (different focus)  |\n\n## 本番環境との対応\n\nClaude Codeは3つの層すべてを実装している。micro-compactionは自動的に行われ、古いツール結果は切り詰められるか要約で置換される。auto-compactionはコンテキストがモデルの上限に近づくとトリガーされ、会話を要約してリセットする。ユーザーは`/compact`で手動圧縮をトリガーすることもできる。トランスクリプトは保存されるため、完全な履歴は決して真に失われず、アクティブなコンテキストの外に移動されるだけだ。本番バージョンでは圧縮されるべきでない「ピン留め」メッセージ(CLAUDE.mdの指示など)も保持される。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s06_compression.py\n```\n\n試せるプロンプト例:\n\n1. `Read every Python file in the agents/ directory one by one`\n   (micro-compactが古い結果を置換するのを観察する)\n2. `Keep reading files until compression triggers automatically`\n3. `Use the compact tool to manually compress the conversation`\n"
  },
  {
    "version": "s06",
    "locale": "zh",
    "title": "s06: Compact (上下文压缩)",
    "content": "# s06: Compact (上下文压缩)\n\n> 三层压缩管道让智能体可以无限期工作: 策略性地遗忘旧的工具结果, token 超过阈值时自动摘要, 以及支持手动触发压缩。\n\n## 问题\n\n上下文窗口是有限的。工具调用积累到足够多时, 消息数组会超过模型的上下文限制, API 调用直接失败。即使在到达硬限制之前, 性能也会下降: 模型变慢、准确率降低, 开始忽略早期消息。\n\n200,000 token 的上下文窗口听起来很大, 但一次 `read_file` 读取 1000 行源文件就消耗约 4000 token。读取 30 个文件、运行 20 条 bash 命令后, 你就已经用掉 100,000+ token 了。没有某种压缩机制, 智能体无法在大型代码库上工作。\n\n三层管道以递增的激进程度来应对这个问题:\n第一层 (micro-compact) 每轮静默替换旧的工具结果。\n第二层 (auto-compact) 在 token 超过阈值时触发完整摘要。\n第三层 (manual compact) 让模型自己触发压缩。\n\n教学简化说明: 这里的 token 估算使用粗略的 字符数/4 启发式方法。生产系统使用专业的 tokenizer 库进行精确计数。\n\n## 解决方案\n\n```\nEvery turn:\n+------------------+\n| Tool call result |\n+------------------+\n        |\n        v\n[Layer 1: micro_compact]        (silent, every turn)\n  Replace tool_result > 3 turns old\n  with \"[Previous: used {tool_name}]\"\n        |\n        v\n[Check: tokens > 50000?]\n   |               |\n   no              yes\n   |               |\n   v               v\ncontinue    [Layer 2: auto_compact]\n              Save transcript to .transcripts/\n              LLM summarizes conversation.\n              Replace all messages with [summary].\n                    |\n                    v\n            [Layer 3: compact tool]\n              Model calls compact explicitly.\n              Same summarization as auto_compact.\n```\n\n## 工作原理\n\n1. **第一层 -- micro_compact**: 每次 LLM 调用前, 找到最近 3 条之前的所有 tool_result 条目, 替换其内容。\n\n```python\ndef micro_compact(messages: list) -> list:\n    tool_results = []\n    for i, msg in enumerate(messages):\n        if msg[\"role\"] == \"user\" and isinstance(msg.get(\"content\"), list):\n            for j, part in enumerate(msg[\"content\"]):\n                if isinstance(part, dict) and part.get(\"type\") == \"tool_result\":\n                    tool_results.append((i, j, part))\n    if len(tool_results) <= KEEP_RECENT:\n        return messages\n    to_clear = tool_results[:-KEEP_RECENT]\n    for _, _, part in to_clear:\n        if len(part.get(\"content\", \"\")) > 100:\n            tool_id = part.get(\"tool_use_id\", \"\")\n            tool_name = tool_name_map.get(tool_id, \"unknown\")\n            part[\"content\"] = f\"[Previous: used {tool_name}]\"\n    return messages\n```\n\n2. **第二层 -- auto_compact**: 当估算 token 超过 50,000 时, 保存完整对话记录并请求 LLM 进行摘要。\n\n```python\ndef auto_compact(messages: list) -> list:\n    TRANSCRIPT_DIR.mkdir(exist_ok=True)\n    transcript_path = TRANSCRIPT_DIR / f\"transcript_{int(time.time())}.jsonl\"\n    with open(transcript_path, \"w\") as f:\n        for msg in messages:\n            f.write(json.dumps(msg, default=str) + \"\\n\")\n    response = client.messages.create(\n        model=MODEL,\n        messages=[{\"role\": \"user\", \"content\":\n            \"Summarize this conversation for continuity...\"\n            + json.dumps(messages, default=str)[:80000]}],\n        max_tokens=2000,\n    )\n    summary = response.content[0].text\n    return [\n        {\"role\": \"user\", \"content\": f\"[Compressed]\\n\\n{summary}\"},\n        {\"role\": \"assistant\", \"content\": \"Understood. Continuing.\"},\n    ]\n```\n\n3. **第三层 -- manual compact**: `compact` 工具按需触发相同的摘要机制。\n\n```python\nif manual_compact:\n    messages[:] = auto_compact(messages)\n```\n\n4. Agent loop 整合了全部三层。\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        micro_compact(messages)\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)\n        response = client.messages.create(...)\n        # ... tool execution ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)\n```\n\n## 核心代码\n\n三层管道 (来自 `agents/s06_compression.py`, 第 67-93 行和第 189-223 行):\n\n```python\nTHRESHOLD = 50000\nKEEP_RECENT = 3\n\ndef micro_compact(messages):\n    # Replace old tool results with placeholders\n    ...\n\ndef auto_compact(messages):\n    # Save transcript, LLM summarize, replace messages\n    ...\n\ndef agent_loop(messages):\n    while True:\n        micro_compact(messages)          # Layer 1\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)  # Layer 2\n        response = client.messages.create(...)\n        # ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)  # Layer 3\n```\n\n## 相对 s05 的变更\n\n| 组件           | 之前 (s05)       | 之后 (s06)                     |\n|----------------|------------------|----------------------------|\n| Tools          | 5                | 5 (基础 + compact)         |\n| 上下文管理     | 无               | 三层压缩                   |\n| Micro-compact  | 无               | 旧结果 -> 占位符           |\n| Auto-compact   | 无               | token 阈值触发             |\n| Manual compact | 无               | `compact` 工具             |\n| Transcripts    | 无               | 保存到 .transcripts/       |\n| Skills         | load_skill       | 已移除 (非本节重点)        |\n\n## 生产环境参考\n\nClaude Code 实现了全部三层。Micro-compaction 自动进行 -- 旧的工具结果被截断或替换为摘要。Auto-compaction 在上下文接近模型限制时触发, 摘要对话并重置。用户也可以通过 `/compact` 手动触发压缩。对话记录被保存, 因此完整历史永远不会真正丢失, 只是从活跃上下文中移出。生产版本还会保留 \"固定\" 消息, 这些消息永远不应被压缩 (比如 CLAUDE.md 指令)。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s06_compression.py\n```\n\n可以尝试的提示:\n\n1. `Read every Python file in the agents/ directory one by one`\n   (观察 micro-compact 替换旧的结果)\n2. `Keep reading files until compression triggers automatically`\n3. `Use the compact tool to manually compress the conversation`\n"
  },
  {
    "version": "s06",
    "locale": "en",
    "title": "s06: Compact",
    "content": "# s06: Compact\n\n> A three-layer compression pipeline lets the agent work indefinitely by strategically forgetting old tool results, auto-summarizing when tokens exceed a threshold, and allowing manual compression on demand.\n\n## The Problem\n\nThe context window is finite. After enough tool calls, the messages array\nexceeds the model's context limit and the API call fails. Even before\nhitting the hard limit, performance degrades: the model becomes slower,\nless accurate, and starts ignoring earlier messages.\n\nA 200,000 token context window sounds large, but a single `read_file` on\na 1000-line source file consumes ~4000 tokens. After reading 30 files and\nrunning 20 bash commands, you are at 100,000+ tokens. The agent cannot\nwork on large codebases without some form of compression.\n\nThe three-layer pipeline addresses this with increasing aggressiveness:\nLayer 1 (micro-compact) silently replaces old tool results every turn.\nLayer 2 (auto-compact) triggers a full summarization when tokens exceed\na threshold. Layer 3 (manual compact) lets the model trigger compression\nitself.\n\nTeaching simplification: the token estimation here uses a rough\ncharacters/4 heuristic. Production systems use proper tokenizer\nlibraries for accurate counts.\n\n## The Solution\n\n```\nEvery turn:\n+------------------+\n| Tool call result |\n+------------------+\n        |\n        v\n[Layer 1: micro_compact]        (silent, every turn)\n  Replace tool_result > 3 turns old\n  with \"[Previous: used {tool_name}]\"\n        |\n        v\n[Check: tokens > 50000?]\n   |               |\n   no              yes\n   |               |\n   v               v\ncontinue    [Layer 2: auto_compact]\n              Save transcript to .transcripts/\n              LLM summarizes conversation.\n              Replace all messages with [summary].\n                    |\n                    v\n            [Layer 3: compact tool]\n              Model calls compact explicitly.\n              Same summarization as auto_compact.\n```\n\n## How It Works\n\n1. **Layer 1 -- micro_compact**: Before each LLM call, find all\n   tool_result entries older than the last 3 and replace their content.\n\n```python\ndef micro_compact(messages: list) -> list:\n    tool_results = []\n    for i, msg in enumerate(messages):\n        if msg[\"role\"] == \"user\" and isinstance(msg.get(\"content\"), list):\n            for j, part in enumerate(msg[\"content\"]):\n                if isinstance(part, dict) and part.get(\"type\") == \"tool_result\":\n                    tool_results.append((i, j, part))\n    if len(tool_results) <= KEEP_RECENT:\n        return messages\n    to_clear = tool_results[:-KEEP_RECENT]\n    for _, _, part in to_clear:\n        if len(part.get(\"content\", \"\")) > 100:\n            tool_id = part.get(\"tool_use_id\", \"\")\n            tool_name = tool_name_map.get(tool_id, \"unknown\")\n            part[\"content\"] = f\"[Previous: used {tool_name}]\"\n    return messages\n```\n\n2. **Layer 2 -- auto_compact**: When estimated tokens exceed 50,000,\n   save the full transcript and ask the LLM to summarize.\n\n```python\ndef auto_compact(messages: list) -> list:\n    TRANSCRIPT_DIR.mkdir(exist_ok=True)\n    transcript_path = TRANSCRIPT_DIR / f\"transcript_{int(time.time())}.jsonl\"\n    with open(transcript_path, \"w\") as f:\n        for msg in messages:\n            f.write(json.dumps(msg, default=str) + \"\\n\")\n    response = client.messages.create(\n        model=MODEL,\n        messages=[{\"role\": \"user\", \"content\":\n            \"Summarize this conversation for continuity...\"\n            + json.dumps(messages, default=str)[:80000]}],\n        max_tokens=2000,\n    )\n    summary = response.content[0].text\n    return [\n        {\"role\": \"user\", \"content\": f\"[Compressed]\\n\\n{summary}\"},\n        {\"role\": \"assistant\", \"content\": \"Understood. Continuing.\"},\n    ]\n```\n\n3. **Layer 3 -- manual compact**: The `compact` tool triggers the same\n   summarization on demand.\n\n```python\nif manual_compact:\n    messages[:] = auto_compact(messages)\n```\n\n4. The agent loop integrates all three layers.\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        micro_compact(messages)\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)\n        response = client.messages.create(...)\n        # ... tool execution ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)\n```\n\n## Key Code\n\nThe three-layer pipeline (from `agents/s06_compression.py`,\nlines 67-93 and 189-223):\n\n```python\nTHRESHOLD = 50000\nKEEP_RECENT = 3\n\ndef micro_compact(messages):\n    # Replace old tool results with placeholders\n    ...\n\ndef auto_compact(messages):\n    # Save transcript, LLM summarize, replace messages\n    ...\n\ndef agent_loop(messages):\n    while True:\n        micro_compact(messages)          # Layer 1\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)  # Layer 2\n        response = client.messages.create(...)\n        # ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)  # Layer 3\n```\n\n## What Changed From s05\n\n| Component      | Before (s05)     | After (s06)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5                | 5 (base + compact)         |\n| Context mgmt   | None             | Three-layer compression    |\n| Micro-compact  | None             | Old results -> placeholders|\n| Auto-compact   | None             | Token threshold trigger    |\n| Manual compact | None             | `compact` tool             |\n| Transcripts    | None             | Saved to .transcripts/     |\n| Skills         | load_skill       | Removed (different focus)  |\n\n## Production Reference\n\nClaude Code implements all three layers. Micro-compaction happens\nautomatically -- old tool results are truncated or replaced with\nsummaries. Auto-compaction triggers when the context approaches the\nmodel's limit, summarizing the conversation and resetting. The user can\nalso trigger manual compaction with `/compact`. Transcripts are saved so\nthe full history is never truly lost, just moved out of the active\ncontext. The production version also preserves \"pinned\" messages that\nshould never be compressed (like CLAUDE.md instructions).\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s06_compression.py\n```\n\nExample prompts to try:\n\n1. `Read every Python file in the agents/ directory one by one`\n   (watch micro-compact replace old results)\n2. `Keep reading files until compression triggers automatically`\n3. `Use the compact tool to manually compress the conversation`\n"
  },
  {
    "version": "s07",
    "locale": "ja",
    "title": "s07: Tasks",
    "content": "# s07: Tasks\n\n> タスクはファイルシステム上にJSON形式で依存グラフ付きで永続化され、コンテキスト圧縮後も生き残り、複数エージェント間で共有できる。\n\n## 問題\n\nインメモリの状態であるTodoManager(s03)は、コンテキストが圧縮(s06)されると失われる。auto_compactがメッセージを要約で置換した後、todoリストは消える。エージェントは要約テキストからそれを再構成しなければならないが、これは不正確でエラーが起きやすい。\n\nこれがs06からs07への重要な橋渡しだ: TodoManagerのアイテムは圧縮と共に死ぬが、ファイルベースのタスクは死なない。状態をファイルシステムに移すことで、圧縮に対する耐性が得られる。\n\nさらに根本的な問題として、インメモリの状態は他のエージェントからは見えない。最終的にチーム(s09以降)を構築する際、チームメイトには共有のタスクボードが必要だ。インメモリのデータ構造はプロセスローカルだ。\n\n解決策はタスクを`.tasks/`にJSON形式で永続化すること。各タスクはID、件名、ステータス、依存グラフを持つ個別のファイルだ。タスク1を完了すると、タスク2が`blockedBy: [1]`を持つ場合、自動的にタスク2のブロックが解除される。ファイルシステムが信頼できる情報源となる。\n\n## 解決策\n\n```\n.tasks/\n  task_1.json  {\"id\":1, \"status\":\"completed\", ...}\n  task_2.json  {\"id\":2, \"blockedBy\":[1], \"status\":\"pending\"}\n  task_3.json  {\"id\":3, \"blockedBy\":[2], \"status\":\"pending\"}\n\nDependency resolution:\n+----------+     +----------+     +----------+\n| task 1   | --> | task 2   | --> | task 3   |\n| complete |     | blocked  |     | blocked  |\n+----------+     +----------+     +----------+\n     |                ^\n     +--- completing task 1 removes it from\n          task 2's blockedBy list\n```\n\n## 仕組み\n\n1. TaskManagerがCRUD操作を提供する。各タスクは1つのJSONファイル。\n\n```python\nclass TaskManager:\n    def create(self, subject: str, description: str = \"\") -> str:\n        task = {\n            \"id\": self._next_id,\n            \"subject\": subject,\n            \"description\": description,\n            \"status\": \"pending\",\n            \"blockedBy\": [],\n            \"blocks\": [],\n            \"owner\": \"\",\n        }\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n```\n\n2. タスクが完了とマークされると、`_clear_dependency`がそのIDを他のすべてのタスクの`blockedBy`リストから除去する。\n\n```python\ndef _clear_dependency(self, completed_id: int):\n    for f in self.dir.glob(\"task_*.json\"):\n        task = json.loads(f.read_text())\n        if completed_id in task.get(\"blockedBy\", []):\n            task[\"blockedBy\"].remove(completed_id)\n            self._save(task)\n```\n\n3. `update`メソッドがステータス変更と双方向の依存関係の結線を処理する。\n\n```python\ndef update(self, task_id, status=None,\n           add_blocked_by=None, add_blocks=None):\n    task = self._load(task_id)\n    if status:\n        task[\"status\"] = status\n        if status == \"completed\":\n            self._clear_dependency(task_id)\n    if add_blocks:\n        task[\"blocks\"] = list(set(task[\"blocks\"] + add_blocks))\n        for blocked_id in add_blocks:\n            blocked = self._load(blocked_id)\n            if task_id not in blocked[\"blockedBy\"]:\n                blocked[\"blockedBy\"].append(task_id)\n                self._save(blocked)\n    self._save(task)\n```\n\n4. 4つのタスクツールがディスパッチマップに追加される。\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"task_create\": lambda **kw: TASKS.create(kw[\"subject\"]),\n    \"task_update\": lambda **kw: TASKS.update(kw[\"task_id\"],\n                       kw.get(\"status\")),\n    \"task_list\":   lambda **kw: TASKS.list_all(),\n    \"task_get\":    lambda **kw: TASKS.get(kw[\"task_id\"]),\n}\n```\n\n## 主要コード\n\n依存グラフ付きTaskManager(`agents/s07_file_tasks.py` 46-123行目):\n\n```python\nclass TaskManager:\n    def __init__(self, tasks_dir: Path):\n        self.dir = tasks_dir\n        self.dir.mkdir(exist_ok=True)\n        self._next_id = self._max_id() + 1\n\n    def _load(self, task_id: int) -> dict:\n        path = self.dir / f\"task_{task_id}.json\"\n        return json.loads(path.read_text())\n\n    def _save(self, task: dict):\n        path = self.dir / f\"task_{task['id']}.json\"\n        path.write_text(json.dumps(task, indent=2))\n\n    def create(self, subject, description=\"\"):\n        task = {\"id\": self._next_id, \"subject\": subject,\n                \"status\": \"pending\", \"blockedBy\": [],\n                \"blocks\": [], \"owner\": \"\"}\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n\n    def _clear_dependency(self, completed_id):\n        for f in self.dir.glob(\"task_*.json\"):\n            task = json.loads(f.read_text())\n            if completed_id in task.get(\"blockedBy\", []):\n                task[\"blockedBy\"].remove(completed_id)\n                self._save(task)\n```\n\n## s06からの変更点\n\n| Component      | Before (s06)     | After (s07)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5                | 8 (+task_create/update/list/get)|\n| State storage  | In-memory only   | JSON files in .tasks/      |\n| Dependencies   | None             | blockedBy + blocks graph   |\n| Compression    | Three-layer      | Removed (different focus)  |\n| Persistence    | Lost on compact  | Survives compression       |\n\n## 本番環境との対応\n\nClaude CodeではTaskツールと`.tasks/`ディレクトリを通じてファイルベースのタスクを実装している。各タスクはステータス追跡と依存関係解決を持つJSONファイルだ。本番バージョンでは優先度レベル、担当者フィールド、チームメッセージングシステムとの統合が追加されている。タスクはコンテキスト圧縮と長時間作業の橋渡しとなる: エージェントは会話の詳細を忘れても、タスクボードが常に何をすべきかを思い出させてくれる。依存グラフにより、エージェントのコンテキストが圧縮された後でもタスクは正しい順序で実行される。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s07_file_tasks.py\n```\n\n試せるプロンプト例:\n\n1. `Create 3 tasks: \"Setup project\", \"Write code\", \"Write tests\". Make them depend on each other in order.`\n2. `List all tasks and show the dependency graph`\n3. `Complete task 1 and then list tasks to see task 2 unblocked`\n4. `Create a task board for refactoring: parse -> transform -> emit -> test`\n"
  },
  {
    "version": "s07",
    "locale": "zh",
    "title": "s07: Tasks (任务系统)",
    "content": "# s07: Tasks (任务系统)\n\n> 任务以 JSON 文件形式持久化在文件系统上, 带有依赖图, 因此它们能在上下文压缩后存活, 也可以跨智能体共享。\n\n## 问题\n\n内存中的状态 (如 s03 的 TodoManager) 在上下文压缩 (s06) 时会丢失。auto_compact 用摘要替换消息后, 待办列表就没了。智能体只能从摘要文本中重建它, 这是有损且容易出错的。\n\n这就是 s06 到 s07 的关键桥梁: TodoManager 的条目随压缩消亡; 基于文件的任务不会。将状态移到文件系统上使其不受压缩影响。\n\n更根本地说, 内存中的状态对其他智能体不可见。当我们最终构建团队 (s09+) 时, 队友需要一个共享的任务看板。内存中的数据结构是进程局部的。\n\n解决方案是将任务作为 JSON 文件持久化在 `.tasks/` 目录中。每个任务是一个单独的文件, 包含 ID、主题、状态和依赖图。完成任务 1 会自动解除任务 2 的阻塞 (如果任务 2 有 `blockedBy: [1]`)。文件系统成为唯一的真实来源。\n\n## 解决方案\n\n```\n.tasks/\n  task_1.json  {\"id\":1, \"status\":\"completed\", ...}\n  task_2.json  {\"id\":2, \"blockedBy\":[1], \"status\":\"pending\"}\n  task_3.json  {\"id\":3, \"blockedBy\":[2], \"status\":\"pending\"}\n\nDependency resolution:\n+----------+     +----------+     +----------+\n| task 1   | --> | task 2   | --> | task 3   |\n| complete |     | blocked  |     | blocked  |\n+----------+     +----------+     +----------+\n     |                ^\n     +--- completing task 1 removes it from\n          task 2's blockedBy list\n```\n\n## 工作原理\n\n1. TaskManager 提供 CRUD 操作。每个任务是一个 JSON 文件。\n\n```python\nclass TaskManager:\n    def create(self, subject: str, description: str = \"\") -> str:\n        task = {\n            \"id\": self._next_id,\n            \"subject\": subject,\n            \"description\": description,\n            \"status\": \"pending\",\n            \"blockedBy\": [],\n            \"blocks\": [],\n            \"owner\": \"\",\n        }\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n```\n\n2. 当任务标记为 completed 时, `_clear_dependency` 将其 ID 从所有其他任务的 `blockedBy` 列表中移除。\n\n```python\ndef _clear_dependency(self, completed_id: int):\n    for f in self.dir.glob(\"task_*.json\"):\n        task = json.loads(f.read_text())\n        if completed_id in task.get(\"blockedBy\", []):\n            task[\"blockedBy\"].remove(completed_id)\n            self._save(task)\n```\n\n3. `update` 方法处理状态变更和双向依赖关联。\n\n```python\ndef update(self, task_id, status=None,\n           add_blocked_by=None, add_blocks=None):\n    task = self._load(task_id)\n    if status:\n        task[\"status\"] = status\n        if status == \"completed\":\n            self._clear_dependency(task_id)\n    if add_blocks:\n        task[\"blocks\"] = list(set(task[\"blocks\"] + add_blocks))\n        for blocked_id in add_blocks:\n            blocked = self._load(blocked_id)\n            if task_id not in blocked[\"blockedBy\"]:\n                blocked[\"blockedBy\"].append(task_id)\n                self._save(blocked)\n    self._save(task)\n```\n\n4. 四个任务工具添加到 dispatch map。\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"task_create\": lambda **kw: TASKS.create(kw[\"subject\"]),\n    \"task_update\": lambda **kw: TASKS.update(kw[\"task_id\"],\n                       kw.get(\"status\")),\n    \"task_list\":   lambda **kw: TASKS.list_all(),\n    \"task_get\":    lambda **kw: TASKS.get(kw[\"task_id\"]),\n}\n```\n\n## 核心代码\n\n带依赖图的 TaskManager (来自 `agents/s07_file_tasks.py`, 第 46-123 行):\n\n```python\nclass TaskManager:\n    def __init__(self, tasks_dir: Path):\n        self.dir = tasks_dir\n        self.dir.mkdir(exist_ok=True)\n        self._next_id = self._max_id() + 1\n\n    def _load(self, task_id: int) -> dict:\n        path = self.dir / f\"task_{task_id}.json\"\n        return json.loads(path.read_text())\n\n    def _save(self, task: dict):\n        path = self.dir / f\"task_{task['id']}.json\"\n        path.write_text(json.dumps(task, indent=2))\n\n    def create(self, subject, description=\"\"):\n        task = {\"id\": self._next_id, \"subject\": subject,\n                \"status\": \"pending\", \"blockedBy\": [],\n                \"blocks\": [], \"owner\": \"\"}\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n\n    def _clear_dependency(self, completed_id):\n        for f in self.dir.glob(\"task_*.json\"):\n            task = json.loads(f.read_text())\n            if completed_id in task.get(\"blockedBy\", []):\n                task[\"blockedBy\"].remove(completed_id)\n                self._save(task)\n```\n\n## 相对 s06 的变更\n\n| 组件           | 之前 (s06)       | 之后 (s07)                           |\n|----------------|------------------|----------------------------------|\n| Tools          | 5                | 8 (+task_create/update/list/get) |\n| 状态存储       | 仅内存           | .tasks/ 中的 JSON 文件           |\n| 依赖关系       | 无               | blockedBy + blocks 图            |\n| 压缩机制       | 三层             | 已移除 (非本节重点)              |\n| 持久化         | 压缩后丢失       | 压缩后存活                       |\n\n## 生产环境参考\n\nClaude Code 通过 Task 工具和 `.tasks/` 目录实现了基于文件的任务。每个任务是一个带有状态追踪和依赖解析的 JSON 文件。生产版本增加了优先级等级、受理人字段以及与团队消息系统的集成。任务是上下文压缩与长期工作之间的桥梁: 智能体可以忘记对话细节, 但始终有任务看板来提醒它还需要做什么。依赖图确保即使在智能体的上下文被压缩后, 任务也按正确的顺序执行。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s07_file_tasks.py\n```\n\n可以尝试的提示:\n\n1. `Create 3 tasks: \"Setup project\", \"Write code\", \"Write tests\". Make them depend on each other in order.`\n2. `List all tasks and show the dependency graph`\n3. `Complete task 1 and then list tasks to see task 2 unblocked`\n4. `Create a task board for refactoring: parse -> transform -> emit -> test`\n"
  },
  {
    "version": "s07",
    "locale": "en",
    "title": "s07: Tasks",
    "content": "# s07: Tasks\n\n> Tasks persist as JSON files on the filesystem with a dependency graph, so they survive context compression and can be shared across agents.\n\n## The Problem\n\nIn-memory state like TodoManager (s03) is lost when the context is\ncompressed (s06). After auto_compact replaces messages with a summary,\nthe todo list is gone. The agent has to reconstruct it from the summary\ntext, which is lossy and error-prone.\n\nThis is the critical s06-to-s07 bridge: TodoManager items die with\ncompression; file-based tasks don't. Moving state to the filesystem\nmakes it compression-proof.\n\nMore fundamentally, in-memory state is invisible to other agents.\nWhen we eventually build teams (s09+), teammates need a shared task\nboard. In-memory data structures are process-local.\n\nThe solution is to persist tasks as JSON files in `.tasks/`. Each task\nis a separate file with an ID, subject, status, and dependency graph.\nCompleting task 1 automatically unblocks task 2 if task 2 has\n`blockedBy: [1]`. The file system becomes the source of truth.\n\n## The Solution\n\n```\n.tasks/\n  task_1.json  {\"id\":1, \"status\":\"completed\", ...}\n  task_2.json  {\"id\":2, \"blockedBy\":[1], \"status\":\"pending\"}\n  task_3.json  {\"id\":3, \"blockedBy\":[2], \"status\":\"pending\"}\n\nDependency resolution:\n+----------+     +----------+     +----------+\n| task 1   | --> | task 2   | --> | task 3   |\n| complete |     | blocked  |     | blocked  |\n+----------+     +----------+     +----------+\n     |                ^\n     +--- completing task 1 removes it from\n          task 2's blockedBy list\n```\n\n## How It Works\n\n1. The TaskManager provides CRUD operations. Each task is a JSON file.\n\n```python\nclass TaskManager:\n    def create(self, subject: str, description: str = \"\") -> str:\n        task = {\n            \"id\": self._next_id,\n            \"subject\": subject,\n            \"description\": description,\n            \"status\": \"pending\",\n            \"blockedBy\": [],\n            \"blocks\": [],\n            \"owner\": \"\",\n        }\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n```\n\n2. When a task is marked completed, `_clear_dependency` removes its ID\n   from all other tasks' `blockedBy` lists.\n\n```python\ndef _clear_dependency(self, completed_id: int):\n    for f in self.dir.glob(\"task_*.json\"):\n        task = json.loads(f.read_text())\n        if completed_id in task.get(\"blockedBy\", []):\n            task[\"blockedBy\"].remove(completed_id)\n            self._save(task)\n```\n\n3. The `update` method handles status changes and bidirectional dependency\n   wiring.\n\n```python\ndef update(self, task_id, status=None,\n           add_blocked_by=None, add_blocks=None):\n    task = self._load(task_id)\n    if status:\n        task[\"status\"] = status\n        if status == \"completed\":\n            self._clear_dependency(task_id)\n    if add_blocks:\n        task[\"blocks\"] = list(set(task[\"blocks\"] + add_blocks))\n        for blocked_id in add_blocks:\n            blocked = self._load(blocked_id)\n            if task_id not in blocked[\"blockedBy\"]:\n                blocked[\"blockedBy\"].append(task_id)\n                self._save(blocked)\n    self._save(task)\n```\n\n4. Four task tools are added to the dispatch map.\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"task_create\": lambda **kw: TASKS.create(kw[\"subject\"]),\n    \"task_update\": lambda **kw: TASKS.update(kw[\"task_id\"],\n                       kw.get(\"status\")),\n    \"task_list\":   lambda **kw: TASKS.list_all(),\n    \"task_get\":    lambda **kw: TASKS.get(kw[\"task_id\"]),\n}\n```\n\n## Key Code\n\nThe TaskManager with dependency graph (from `agents/s07_file_tasks.py`,\nlines 46-123):\n\n```python\nclass TaskManager:\n    def __init__(self, tasks_dir: Path):\n        self.dir = tasks_dir\n        self.dir.mkdir(exist_ok=True)\n        self._next_id = self._max_id() + 1\n\n    def _load(self, task_id: int) -> dict:\n        path = self.dir / f\"task_{task_id}.json\"\n        return json.loads(path.read_text())\n\n    def _save(self, task: dict):\n        path = self.dir / f\"task_{task['id']}.json\"\n        path.write_text(json.dumps(task, indent=2))\n\n    def create(self, subject, description=\"\"):\n        task = {\"id\": self._next_id, \"subject\": subject,\n                \"status\": \"pending\", \"blockedBy\": [],\n                \"blocks\": [], \"owner\": \"\"}\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n\n    def _clear_dependency(self, completed_id):\n        for f in self.dir.glob(\"task_*.json\"):\n            task = json.loads(f.read_text())\n            if completed_id in task.get(\"blockedBy\", []):\n                task[\"blockedBy\"].remove(completed_id)\n                self._save(task)\n```\n\n## What Changed From s06\n\n| Component      | Before (s06)     | After (s07)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5                | 8 (+task_create/update/list/get)|\n| State storage  | In-memory only   | JSON files in .tasks/      |\n| Dependencies   | None             | blockedBy + blocks graph   |\n| Compression    | Three-layer      | Removed (different focus)  |\n| Persistence    | Lost on compact  | Survives compression       |\n\n## Production Reference\n\nClaude Code implements file-based tasks through the Task tool and\n`.tasks/` directory. Each task is a JSON file with status tracking and\ndependency resolution. The production version adds priority levels,\nassignee fields, and integration with the team messaging system. Tasks\nare the bridge between context compression and long-running work: the\nagent can forget conversation details but always has the task board to\nremind it what needs doing. The dependency graph ensures tasks execute\nin the correct order even when the agent's context has been compressed.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s07_file_tasks.py\n```\n\nExample prompts to try:\n\n1. `Create 3 tasks: \"Setup project\", \"Write code\", \"Write tests\". Make them depend on each other in order.`\n2. `List all tasks and show the dependency graph`\n3. `Complete task 1 and then list tasks to see task 2 unblocked`\n4. `Create a task board for refactoring: parse -> transform -> emit -> test`\n"
  },
  {
    "version": "s08",
    "locale": "ja",
    "title": "s08: Background Tasks",
    "content": "# s08: Background Tasks\n\n> BackgroundManagerがコマンドを別スレッドで実行し、各LLM呼び出しの前に通知キューをドレインすることで、エージェントは長時間実行操作でブロックされなくなる。\n\n## 問題\n\n一部のコマンドは数分かかる: `npm install`、`pytest`、`docker build`。ブロッキングのagent loopでは、モデルはサブプロセスの終了を待って待機する。他のことは何もできない。ユーザーが「依存関係をインストールして、その間にconfigファイルを作成して」と言った場合、エージェントはまずインストールを行い、その後configを作成する -- 並列ではなく逐次的に。\n\nエージェントには並行性が必要だ。agent loop自体の完全なマルチスレッディングではなく、長いコマンドを発射して実行中に作業を続ける能力だ。コマンドが終了したら、その結果は自然に会話に現れるべきだ。\n\n解決策は、BackgroundManagerがコマンドをデーモンスレッドで実行し、結果を通知キューに収集すること。各LLM呼び出しの前にキューがドレインされ、結果がメッセージに注入される。\n\n## 解決策\n\n```\nMain thread                Background thread\n+-----------------+        +-----------------+\n| agent loop      |        | task executes   |\n| ...             |        | ...             |\n| [LLM call] <---+------- | enqueue(result) |\n|  ^drain queue   |        +-----------------+\n+-----------------+\n\nTimeline:\nAgent --[spawn A]--[spawn B]--[other work]----\n             |          |\n             v          v\n          [A runs]   [B runs]      (parallel)\n             |          |\n             +-- notification queue --+\n                                      |\n                           [results injected before\n                            next LLM call]\n```\n\n## 仕組み\n\n1. BackgroundManagerがタスクを追跡し、スレッドセーフな通知キューを維持する。\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n```\n\n2. `run()`がデーモンスレッドを開始し、task_idを即座に返す。\n\n```python\ndef run(self, command: str) -> str:\n    task_id = str(uuid.uuid4())[:8]\n    self.tasks[task_id] = {\n        \"status\": \"running\",\n        \"result\": None,\n        \"command\": command,\n    }\n    thread = threading.Thread(\n        target=self._execute,\n        args=(task_id, command),\n        daemon=True,\n    )\n    thread.start()\n    return f\"Background task {task_id} started\"\n```\n\n3. スレッドのターゲットである`_execute`がサブプロセスを実行し、結果を通知キューにプッシュする。\n\n```python\ndef _execute(self, task_id: str, command: str):\n    try:\n        r = subprocess.run(command, shell=True, cwd=WORKDIR,\n            capture_output=True, text=True, timeout=300)\n        output = (r.stdout + r.stderr).strip()[:50000]\n        status = \"completed\"\n    except subprocess.TimeoutExpired:\n        output = \"Error: Timeout (300s)\"\n        status = \"timeout\"\n    self.tasks[task_id][\"status\"] = status\n    self.tasks[task_id][\"result\"] = output\n    with self._lock:\n        self._notification_queue.append({\n            \"task_id\": task_id,\n            \"status\": status,\n            \"result\": output[:500],\n        })\n```\n\n4. `drain_notifications()`が保留中の結果を返してクリアする。\n\n```python\ndef drain_notifications(self) -> list:\n    with self._lock:\n        notifs = list(self._notification_queue)\n        self._notification_queue.clear()\n    return notifs\n```\n\n5. agent loopが各LLM呼び出しの前に通知をドレインする。\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        notifs = BG.drain_notifications()\n        if notifs and messages:\n            notif_text = \"\\n\".join(\n                f\"[bg:{n['task_id']}] {n['status']}: \"\n                f\"{n['result']}\" for n in notifs\n            )\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<background-results>\"\n                           f\"\\n{notif_text}\\n\"\n                           f\"</background-results>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted background results.\"})\n        response = client.messages.create(...)\n```\n\n## 主要コード\n\nBackgroundManager(`agents/s08_background.py` 49-107行目):\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n\n    def run(self, command: str) -> str:\n        task_id = str(uuid.uuid4())[:8]\n        self.tasks[task_id] = {\"status\": \"running\",\n                               \"result\": None,\n                               \"command\": command}\n        thread = threading.Thread(\n            target=self._execute,\n            args=(task_id, command), daemon=True)\n        thread.start()\n        return f\"Background task {task_id} started\"\n\n    def _execute(self, task_id, command):\n        # run subprocess, push to queue\n        ...\n\n    def drain_notifications(self) -> list:\n        with self._lock:\n            notifs = list(self._notification_queue)\n            self._notification_queue.clear()\n        return notifs\n```\n\n## s07からの変更点\n\n| Component      | Before (s07)     | After (s08)                |\n|----------------|------------------|----------------------------|\n| Tools          | 8                | 6 (base + background_run + check)|\n| Execution      | Blocking only    | Blocking + background threads|\n| Notification   | None             | Queue drained per loop     |\n| Concurrency    | None             | Daemon threads             |\n| Task system    | File-based CRUD  | Removed (different focus)  |\n\n## 本番環境との対応\n\nClaude Codeではバックグラウンドタスクを別プロセスとして実行する。テストスイートやビルドなどの長時間実行コマンドは非同期で起動され、結果は通知システムを通じてエージェントに配信される。本番バージョンではクリーンアップのためのプロセスグループ、進捗報告、キャンセルサポートが追加されている。LLM呼び出し前のドレインパターンにより、バックグラウンド結果は思考の途中で割り込むのではなく、会話の自然な切れ目で到着する。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s08_background.py\n```\n\n試せるプロンプト例:\n\n1. `Run \"sleep 5 && echo done\" in the background, then create a file while it runs`\n2. `Start 3 background tasks: \"sleep 2\", \"sleep 4\", \"sleep 6\". Check their status.`\n3. `Run pytest in the background and keep working on other things`\n"
  },
  {
    "version": "s08",
    "locale": "zh",
    "title": "s08: Background Tasks (后台任务)",
    "content": "# s08: Background Tasks (后台任务)\n\n> BackgroundManager 在独立线程中运行命令, 在每次 LLM 调用前排空通知队列, 使智能体永远不会因长时间运行的操作而阻塞。\n\n## 问题\n\n有些命令需要几分钟: `npm install`、`pytest`、`docker build`。在阻塞式的 agent loop 中, 模型只能干等子进程结束, 什么也做不了。如果用户要求 \"安装依赖, 同时创建配置文件\", 智能体会先安装, 然后才创建配置 -- 串行执行, 而非并行。\n\n智能体需要并发能力。不是将 agent loop 本身完全多线程化, 而是能够发起一个长时间命令然后继续工作。当命令完成时, 结果自然地出现在对话中。\n\n解决方案是一个 BackgroundManager, 它在守护线程中运行命令, 将结果收集到通知队列中。每次 LLM 调用前, 队列被排空, 结果注入到消息中。\n\n## 解决方案\n\n```\nMain thread                Background thread\n+-----------------+        +-----------------+\n| agent loop      |        | task executes   |\n| ...             |        | ...             |\n| [LLM call] <---+------- | enqueue(result) |\n|  ^drain queue   |        +-----------------+\n+-----------------+\n\nTimeline:\nAgent --[spawn A]--[spawn B]--[other work]----\n             |          |\n             v          v\n          [A runs]   [B runs]      (parallel)\n             |          |\n             +-- notification queue --+\n                                      |\n                           [results injected before\n                            next LLM call]\n```\n\n## 工作原理\n\n1. BackgroundManager 追踪任务并维护一个线程安全的通知队列。\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n```\n\n2. `run()` 启动一个守护线程并立即返回 task_id。\n\n```python\ndef run(self, command: str) -> str:\n    task_id = str(uuid.uuid4())[:8]\n    self.tasks[task_id] = {\n        \"status\": \"running\",\n        \"result\": None,\n        \"command\": command,\n    }\n    thread = threading.Thread(\n        target=self._execute,\n        args=(task_id, command),\n        daemon=True,\n    )\n    thread.start()\n    return f\"Background task {task_id} started\"\n```\n\n3. 线程目标函数 `_execute` 运行子进程并将结果推入通知队列。\n\n```python\ndef _execute(self, task_id: str, command: str):\n    try:\n        r = subprocess.run(command, shell=True, cwd=WORKDIR,\n            capture_output=True, text=True, timeout=300)\n        output = (r.stdout + r.stderr).strip()[:50000]\n        status = \"completed\"\n    except subprocess.TimeoutExpired:\n        output = \"Error: Timeout (300s)\"\n        status = \"timeout\"\n    self.tasks[task_id][\"status\"] = status\n    self.tasks[task_id][\"result\"] = output\n    with self._lock:\n        self._notification_queue.append({\n            \"task_id\": task_id,\n            \"status\": status,\n            \"result\": output[:500],\n        })\n```\n\n4. `drain_notifications()` 返回并清空待处理的结果。\n\n```python\ndef drain_notifications(self) -> list:\n    with self._lock:\n        notifs = list(self._notification_queue)\n        self._notification_queue.clear()\n    return notifs\n```\n\n5. Agent loop 在每次 LLM 调用前排空通知。\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        notifs = BG.drain_notifications()\n        if notifs and messages:\n            notif_text = \"\\n\".join(\n                f\"[bg:{n['task_id']}] {n['status']}: \"\n                f\"{n['result']}\" for n in notifs\n            )\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<background-results>\"\n                           f\"\\n{notif_text}\\n\"\n                           f\"</background-results>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted background results.\"})\n        response = client.messages.create(...)\n```\n\n## 核心代码\n\nBackgroundManager (来自 `agents/s08_background.py`, 第 49-107 行):\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n\n    def run(self, command: str) -> str:\n        task_id = str(uuid.uuid4())[:8]\n        self.tasks[task_id] = {\"status\": \"running\",\n                               \"result\": None,\n                               \"command\": command}\n        thread = threading.Thread(\n            target=self._execute,\n            args=(task_id, command), daemon=True)\n        thread.start()\n        return f\"Background task {task_id} started\"\n\n    def _execute(self, task_id, command):\n        # run subprocess, push to queue\n        ...\n\n    def drain_notifications(self) -> list:\n        with self._lock:\n            notifs = list(self._notification_queue)\n            self._notification_queue.clear()\n        return notifs\n```\n\n## 相对 s07 的变更\n\n| 组件           | 之前 (s07)       | 之后 (s08)                         |\n|----------------|------------------|------------------------------------|\n| Tools          | 8                | 6 (基础 + background_run + check)  |\n| 执行方式       | 仅阻塞           | 阻塞 + 后台线程                    |\n| 通知机制       | 无               | 每轮排空的队列                     |\n| 并发           | 无               | 守护线程                           |\n| 任务系统       | 基于文件的 CRUD  | 已移除 (非本节重点)                |\n\n## 生产环境参考\n\nClaude Code 以独立进程运行后台任务。测试套件或构建等长时间运行的命令被异步启动, 其结果通过通知系统传递给智能体。生产版本增加了进程组清理、进度报告和取消支持。\"在 LLM 调用前排空\" 的模式确保后台结果在对话的自然间断点到达, 而不是打断思考过程。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s08_background.py\n```\n\n可以尝试的提示:\n\n1. `Run \"sleep 5 && echo done\" in the background, then create a file while it runs`\n2. `Start 3 background tasks: \"sleep 2\", \"sleep 4\", \"sleep 6\". Check their status.`\n3. `Run pytest in the background and keep working on other things`\n"
  },
  {
    "version": "s08",
    "locale": "en",
    "title": "s08: Background Tasks",
    "content": "# s08: Background Tasks\n\n> A BackgroundManager runs commands in separate threads and drains a notification queue before each LLM call, so the agent never blocks on long-running operations.\n\n## The Problem\n\nSome commands take minutes: `npm install`, `pytest`, `docker build`. With\na blocking agent loop, the model sits idle waiting for the subprocess to\nfinish. It cannot do anything else. If the user asked \"install dependencies\nand while that runs, create the config file,\" the agent would install\nfirst, _then_ create the config -- sequentially, not in parallel.\n\nThe agent needs concurrency. Not full multi-threading of the agent loop\nitself, but the ability to fire off a long command and continue working\nwhile it runs. When the command finishes, its result should appear\nnaturally in the conversation.\n\nThe solution is a BackgroundManager that runs commands in daemon threads\nand collects results in a notification queue. Before each LLM call, the\nqueue is drained and results are injected into the messages.\n\n## The Solution\n\n```\nMain thread                Background thread\n+-----------------+        +-----------------+\n| agent loop      |        | task executes   |\n| ...             |        | ...             |\n| [LLM call] <---+------- | enqueue(result) |\n|  ^drain queue   |        +-----------------+\n+-----------------+\n\nTimeline:\nAgent --[spawn A]--[spawn B]--[other work]----\n             |          |\n             v          v\n          [A runs]   [B runs]      (parallel)\n             |          |\n             +-- notification queue --+\n                                      |\n                           [results injected before\n                            next LLM call]\n```\n\n## How It Works\n\n1. The BackgroundManager tracks tasks and maintains a thread-safe\n   notification queue.\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n```\n\n2. `run()` starts a daemon thread and returns a task_id immediately.\n\n```python\ndef run(self, command: str) -> str:\n    task_id = str(uuid.uuid4())[:8]\n    self.tasks[task_id] = {\n        \"status\": \"running\",\n        \"result\": None,\n        \"command\": command,\n    }\n    thread = threading.Thread(\n        target=self._execute,\n        args=(task_id, command),\n        daemon=True,\n    )\n    thread.start()\n    return f\"Background task {task_id} started\"\n```\n\n3. The thread target `_execute` runs the subprocess and pushes\n   results to the notification queue.\n\n```python\ndef _execute(self, task_id: str, command: str):\n    try:\n        r = subprocess.run(command, shell=True, cwd=WORKDIR,\n            capture_output=True, text=True, timeout=300)\n        output = (r.stdout + r.stderr).strip()[:50000]\n        status = \"completed\"\n    except subprocess.TimeoutExpired:\n        output = \"Error: Timeout (300s)\"\n        status = \"timeout\"\n    self.tasks[task_id][\"status\"] = status\n    self.tasks[task_id][\"result\"] = output\n    with self._lock:\n        self._notification_queue.append({\n            \"task_id\": task_id,\n            \"status\": status,\n            \"result\": output[:500],\n        })\n```\n\n4. `drain_notifications()` returns and clears pending results.\n\n```python\ndef drain_notifications(self) -> list:\n    with self._lock:\n        notifs = list(self._notification_queue)\n        self._notification_queue.clear()\n    return notifs\n```\n\n5. The agent loop drains notifications before each LLM call.\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        notifs = BG.drain_notifications()\n        if notifs and messages:\n            notif_text = \"\\n\".join(\n                f\"[bg:{n['task_id']}] {n['status']}: \"\n                f\"{n['result']}\" for n in notifs\n            )\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<background-results>\"\n                           f\"\\n{notif_text}\\n\"\n                           f\"</background-results>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted background results.\"})\n        response = client.messages.create(...)\n```\n\n## Key Code\n\nThe BackgroundManager (from `agents/s08_background.py`, lines 49-107):\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n\n    def run(self, command: str) -> str:\n        task_id = str(uuid.uuid4())[:8]\n        self.tasks[task_id] = {\"status\": \"running\",\n                               \"result\": None,\n                               \"command\": command}\n        thread = threading.Thread(\n            target=self._execute,\n            args=(task_id, command), daemon=True)\n        thread.start()\n        return f\"Background task {task_id} started\"\n\n    def _execute(self, task_id, command):\n        # run subprocess, push to queue\n        ...\n\n    def drain_notifications(self) -> list:\n        with self._lock:\n            notifs = list(self._notification_queue)\n            self._notification_queue.clear()\n        return notifs\n```\n\n## What Changed From s07\n\n| Component      | Before (s07)     | After (s08)                |\n|----------------|------------------|----------------------------|\n| Tools          | 8                | 6 (base + background_run + check)|\n| Execution      | Blocking only    | Blocking + background threads|\n| Notification   | None             | Queue drained per loop     |\n| Concurrency    | None             | Daemon threads             |\n| Task system    | File-based CRUD  | Removed (different focus)  |\n\n## Production Reference\n\nClaude Code runs background tasks as separate processes. Long-running\ncommands like test suites or builds are launched asynchronously, and\ntheir results are delivered to the agent through a notification system.\nThe production version adds process groups for cleanup, progress\nreporting, and cancellation support. The drain-before-LLM-call pattern\nensures background results arrive at a natural point in the conversation\nrather than interrupting mid-thought.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s08_background.py\n```\n\nExample prompts to try:\n\n1. `Run \"sleep 5 && echo done\" in the background, then create a file while it runs`\n2. `Start 3 background tasks: \"sleep 2\", \"sleep 4\", \"sleep 6\". Check their status.`\n3. `Run pytest in the background and keep working on other things`\n"
  },
  {
    "version": "s09",
    "locale": "ja",
    "title": "s09: Agent Teams",
    "content": "# s09: Agent Teams\n\n> JSONL形式のインボックスを持つ永続的なチームメイトが、孤立したエージェントをコミュニケーションするチームに変える -- spawn、message、broadcast、drain。\n\n## 問題\n\nサブエージェント(s04)は使い捨てだ: 生成し、作業し、要約を返し、消滅する。アイデンティティもなく、呼び出し間の記憶もなく、フォローアップの指示を受け取る方法もない。バックグラウンドタスク(s08)はシェルコマンドを実行するが、LLM誘導の意思決定やフィードバックの伝達はできない。\n\n本物のチームワークには3つのものが必要だ: (1)単一のプロンプトを超えて存続する永続的なエージェント、(2)アイデンティティとライフサイクル管理、(3)エージェント間の通信チャネル。メッセージングがなければ、永続的なチームメイトでさえ聾唖だ -- 並列に作業できるが協調することはない。\n\n解決策は、名前付きの永続的エージェントを生成するTeammateManagerと、JONSLインボックスファイルを使うMessageBusの組み合わせだ。各チームメイトは自身のagent loopをスレッドで実行し、各LLM呼び出しの前にインボックスを確認し、他のチームメイトやリーダーにメッセージを送れる。\n\ns06からs07への橋渡しについての注記: s03のTodoManagerアイテムは圧縮(s06)と共に死ぬ。ファイルベースのタスク(s07)はディスク上に存在するため圧縮後も生き残る。チームも同じ原則の上に構築されている -- config.jsonとインボックスファイルはコンテキストウィンドウの外に永続化される。\n\n## 解決策\n\n```\nTeammate lifecycle:\n  spawn -> WORKING -> IDLE -> WORKING -> ... -> SHUTDOWN\n\nCommunication:\n  .team/\n    config.json           <- team roster + statuses\n    inbox/\n      alice.jsonl         <- append-only, drain-on-read\n      bob.jsonl\n      lead.jsonl\n\n                +--------+    send(\"alice\",\"bob\",\"...\")    +--------+\n                | alice  | -----------------------------> |  bob   |\n                | loop   |    bob.jsonl << {json_line}    |  loop  |\n                +--------+                                +--------+\n                     ^                                         |\n                     |        BUS.read_inbox(\"alice\")          |\n                     +---- alice.jsonl -> read + drain ---------+\n\n5 message types:\n+-------------------------+------------------------------+\n| message                 | Normal text between agents   |\n| broadcast               | Sent to all teammates        |\n| shutdown_request        | Request graceful shutdown     |\n| shutdown_response       | Approve/reject shutdown      |\n| plan_approval_response  | Approve/reject plan          |\n+-------------------------+------------------------------+\n```\n\n## 仕組み\n\n1. TeammateManagerがチームの名簿としてconfig.jsonを管理する。各メンバーは名前、役割、ステータスを持つ。\n\n```python\nclass TeammateManager:\n    def __init__(self, team_dir: Path):\n        self.dir = team_dir\n        self.dir.mkdir(exist_ok=True)\n        self.config_path = self.dir / \"config.json\"\n        self.config = self._load_config()\n        self.threads = {}\n```\n\n2. `spawn()`がチームメイトを作成し、そのagent loopをスレッドで開始する。アイドル状態のチームメイトを再spawnすると再活性化される。\n\n```python\ndef spawn(self, name: str, role: str, prompt: str) -> str:\n    member = self._find_member(name)\n    if member:\n        if member[\"status\"] not in (\"idle\", \"shutdown\"):\n            return f\"Error: '{name}' is currently {member['status']}\"\n        member[\"status\"] = \"working\"\n    else:\n        member = {\"name\": name, \"role\": role, \"status\": \"working\"}\n        self.config[\"members\"].append(member)\n    self._save_config()\n    thread = threading.Thread(\n        target=self._teammate_loop,\n        args=(name, role, prompt), daemon=True)\n    self.threads[name] = thread\n    thread.start()\n    return f\"Spawned teammate '{name}' (role: {role})\"\n```\n\n3. MessageBusがJSONLインボックスファイルを処理する。`send()`がJSON行を追記し、`read_inbox()`がすべての行を読み取ってファイルをドレインする。\n\n```python\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content,\n               \"timestamp\": time.time()}\n        if extra:\n            msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n        return f\"Sent {msg_type} to {to}\"\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists():\n            return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")  # drain\n        return json.dumps(msgs, indent=2)\n```\n\n4. 各チームメイトは各LLM呼び出しの前にインボックスを確認し、受信メッセージを会話コンテキストに注入する。\n\n```python\ndef _teammate_loop(self, name, role, prompt):\n    sys_prompt = f\"You are '{name}', role: {role}, at {WORKDIR}.\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(50):\n        inbox = BUS.read_inbox(name)\n        if inbox != \"[]\":\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted inbox messages.\"})\n        response = client.messages.create(\n            model=MODEL, system=sys_prompt,\n            messages=messages, tools=TOOLS)\n        messages.append({\"role\": \"assistant\",\n                         \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n    self._find_member(name)[\"status\"] = \"idle\"\n    self._save_config()\n```\n\n5. `broadcast()`が送信者以外の全チームメイトに同じメッセージを送信する。\n\n```python\ndef broadcast(self, sender, content, teammates):\n    count = 0\n    for name in teammates:\n        if name != sender:\n            self.send(sender, name, content, \"broadcast\")\n            count += 1\n    return f\"Broadcast to {count} teammates\"\n```\n\n## 主要コード\n\nTeammateManager + MessageBusのコア(`agents/s09_team_messaging.py`):\n\n```python\nclass TeammateManager:\n    def spawn(self, name, role, prompt):\n        member = self._find_member(name) or {\n            \"name\": name, \"role\": role, \"status\": \"working\"\n        }\n        member[\"status\"] = \"working\"\n        self._save_config()\n        thread = threading.Thread(\n            target=self._teammate_loop,\n            args=(name, role, prompt), daemon=True)\n        thread.start()\n        return f\"Spawned '{name}'\"\n\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content, \"timestamp\": time.time()}\n        if extra: msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists(): return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")\n        return json.dumps(msgs, indent=2)\n```\n\n## s08からの変更点\n\n| Component      | Before (s08)     | After (s09)                |\n|----------------|------------------|----------------------------|\n| Tools          | 6                | 9 (+spawn/send/read_inbox) |\n| Agents         | Single           | Lead + N teammates         |\n| Persistence    | None             | config.json + JSONL inboxes|\n| Threads        | Background cmds  | Full agent loops per thread|\n| Lifecycle      | Fire-and-forget  | idle -> working -> idle    |\n| Communication  | None             | 5 message types + broadcast|\n\n教育上の簡略化: この実装ではインボックスアクセスにロックファイルを使用していない。本番環境では、複数ライターからの並行追記にはファイルロッキングまたはアトミックリネームが必要になる。ここで使用している単一ライター/インボックスパターンは教育シナリオでは安全だ。\n\n## 本番環境との対応\n\nClaude CodeではTeammateManagerによるチームメイト管理とSendMessageツールによるJSONLインボックスファイルを通じたメッセージングを実装している。本番システムは同じ5つのメッセージタイプをサポートし、同じappend/drainパターンを使用する。メッセージは非同期で配信される -- 送信者は受信者が読むのを待ってブロックしない。各LLM呼び出し前のインボックスチェックにより、メッセージは思考の途中ではなく会話の自然な区切りで到着する。本番環境ではメッセージの重複排除、サイズ制限、適切なファイルロッキングが追加されている。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s09_team_messaging.py\n```\n\n試せるプロンプト例:\n\n1. `Spawn alice (coder) and bob (tester). Have alice send bob a message.`\n2. `Broadcast \"status update: phase 1 complete\" to all teammates`\n3. `Check the lead inbox for any messages`\n4. `/team`と入力してステータス付きのチーム名簿を確認する\n5. `/inbox`と入力してリーダーのインボックスを手動確認する\n"
  },
  {
    "version": "s09",
    "locale": "zh",
    "title": "s09: Agent Teams (智能体团队)",
    "content": "# s09: Agent Teams (智能体团队)\n\n> 持久化的队友通过 JSONL 收件箱将孤立的智能体转变为可通信的团队 -- spawn、message、broadcast 和 drain。\n\n## 问题\n\n子智能体 (s04) 是一次性的: 生成、工作、返回摘要、消亡。它们没有身份, 没有跨调用的记忆, 也无法接收后续指令。后台任务 (s08) 运行 shell 命令, 但不能做 LLM 引导的决策或交流发现。\n\n真正的团队协作需要三样东西: (1) 存活时间超过单次 prompt 的持久化智能体, (2) 身份和生命周期管理, (3) 智能体之间的通信通道。没有消息机制, 即使持久化的队友也是又聋又哑的 -- 它们可以并行工作但永远无法协调。\n\n解决方案将 TeammateManager (用于生成持久化的命名智能体) 与使用 JSONL 收件箱文件的 MessageBus 结合。每个队友在独立线程中运行自己的 agent loop, 每次 LLM 调用前检查收件箱, 可以向任何其他队友或领导发送消息。\n\n关于 s06 到 s07 的桥梁: s03 的 TodoManager 条目随压缩 (s06) 消亡。基于文件的任务 (s07) 因为存储在磁盘上而能存活压缩。团队建立在同样的原则上 -- config.json 和收件箱文件持久化在上下文窗口之外。\n\n## 解决方案\n\n```\nTeammate lifecycle:\n  spawn -> WORKING -> IDLE -> WORKING -> ... -> SHUTDOWN\n\nCommunication:\n  .team/\n    config.json           <- team roster + statuses\n    inbox/\n      alice.jsonl         <- append-only, drain-on-read\n      bob.jsonl\n      lead.jsonl\n\n                +--------+    send(\"alice\",\"bob\",\"...\")    +--------+\n                | alice  | -----------------------------> |  bob   |\n                | loop   |    bob.jsonl << {json_line}    |  loop  |\n                +--------+                                +--------+\n                     ^                                         |\n                     |        BUS.read_inbox(\"alice\")          |\n                     +---- alice.jsonl -> read + drain ---------+\n\n5 message types:\n+-------------------------+------------------------------+\n| message                 | Normal text between agents   |\n| broadcast               | Sent to all teammates        |\n| shutdown_request        | Request graceful shutdown     |\n| shutdown_response       | Approve/reject shutdown      |\n| plan_approval_response  | Approve/reject plan          |\n+-------------------------+------------------------------+\n```\n\n## 工作原理\n\n1. TeammateManager 通过 config.json 维护团队名册。每个成员有名称、角色和状态。\n\n```python\nclass TeammateManager:\n    def __init__(self, team_dir: Path):\n        self.dir = team_dir\n        self.dir.mkdir(exist_ok=True)\n        self.config_path = self.dir / \"config.json\"\n        self.config = self._load_config()\n        self.threads = {}\n```\n\n2. `spawn()` 创建队友并在线程中启动其 agent loop。重新 spawn 一个 idle 状态的队友会将其重新激活。\n\n```python\ndef spawn(self, name: str, role: str, prompt: str) -> str:\n    member = self._find_member(name)\n    if member:\n        if member[\"status\"] not in (\"idle\", \"shutdown\"):\n            return f\"Error: '{name}' is currently {member['status']}\"\n        member[\"status\"] = \"working\"\n    else:\n        member = {\"name\": name, \"role\": role, \"status\": \"working\"}\n        self.config[\"members\"].append(member)\n    self._save_config()\n    thread = threading.Thread(\n        target=self._teammate_loop,\n        args=(name, role, prompt), daemon=True)\n    self.threads[name] = thread\n    thread.start()\n    return f\"Spawned teammate '{name}' (role: {role})\"\n```\n\n3. MessageBus 处理 JSONL 收件箱文件。`send()` 追加一行 JSON; `read_inbox()` 读取所有行并清空文件。\n\n```python\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content,\n               \"timestamp\": time.time()}\n        if extra:\n            msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n        return f\"Sent {msg_type} to {to}\"\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists():\n            return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")  # drain\n        return json.dumps(msgs, indent=2)\n```\n\n4. 每个队友在每次 LLM 调用前检查收件箱, 将收到的消息注入对话上下文。\n\n```python\ndef _teammate_loop(self, name, role, prompt):\n    sys_prompt = f\"You are '{name}', role: {role}, at {WORKDIR}.\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(50):\n        inbox = BUS.read_inbox(name)\n        if inbox != \"[]\":\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted inbox messages.\"})\n        response = client.messages.create(\n            model=MODEL, system=sys_prompt,\n            messages=messages, tools=TOOLS)\n        messages.append({\"role\": \"assistant\",\n                         \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n    self._find_member(name)[\"status\"] = \"idle\"\n    self._save_config()\n```\n\n5. `broadcast()` 向除发送者外的所有队友发送相同消息。\n\n```python\ndef broadcast(self, sender, content, teammates):\n    count = 0\n    for name in teammates:\n        if name != sender:\n            self.send(sender, name, content, \"broadcast\")\n            count += 1\n    return f\"Broadcast to {count} teammates\"\n```\n\n## 核心代码\n\nTeammateManager + MessageBus 核心 (来自 `agents/s09_team_messaging.py`):\n\n```python\nclass TeammateManager:\n    def spawn(self, name, role, prompt):\n        member = self._find_member(name) or {\n            \"name\": name, \"role\": role, \"status\": \"working\"\n        }\n        member[\"status\"] = \"working\"\n        self._save_config()\n        thread = threading.Thread(\n            target=self._teammate_loop,\n            args=(name, role, prompt), daemon=True)\n        thread.start()\n        return f\"Spawned '{name}'\"\n\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content, \"timestamp\": time.time()}\n        if extra: msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists(): return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")\n        return json.dumps(msgs, indent=2)\n```\n\n## 相对 s08 的变更\n\n| 组件           | 之前 (s08)       | 之后 (s09)                         |\n|----------------|------------------|------------------------------------|\n| Tools          | 6                | 9 (+spawn/send/read_inbox)         |\n| 智能体数量     | 单一             | 领导 + N 个队友                    |\n| 持久化         | 无               | config.json + JSONL 收件箱         |\n| 线程           | 后台命令         | 每线程完整 agent loop              |\n| 生命周期       | 一次性           | idle -> working -> idle            |\n| 通信           | 无               | 5 种消息类型 + broadcast           |\n\n教学简化说明: 此实现未使用文件锁来保护收件箱访问。在生产中, 多个写入者并发追加需要文件锁或原子重命名。这里使用的单写入者-per-收件箱模式在教学场景下是安全的。\n\n## 生产环境参考\n\nClaude Code 通过 TeammateManager 实现队友管理, 通过 SendMessage 工具和 JSONL 收件箱文件实现消息传递。生产系统支持同样的 5 种消息类型并使用同样的追加/排空模式。消息异步传递 -- 发送者不会阻塞等待接收者读取。每次 LLM 调用前检查收件箱确保消息在对话的自然间断点到达。生产版本增加了消息去重、大小限制和适当的文件锁。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s09_team_messaging.py\n```\n\n可以尝试的提示:\n\n1. `Spawn alice (coder) and bob (tester). Have alice send bob a message.`\n2. `Broadcast \"status update: phase 1 complete\" to all teammates`\n3. `Check the lead inbox for any messages`\n4. 输入 `/team` 查看带状态的团队名册\n5. 输入 `/inbox` 手动检查领导的收件箱\n"
  },
  {
    "version": "s09",
    "locale": "en",
    "title": "s09: Agent Teams",
    "content": "# s09: Agent Teams\n\n> Persistent teammates with JSONL inboxes turn isolated agents into a communicating team -- spawn, message, broadcast, and drain.\n\n## The Problem\n\nSubagents (s04) are disposable: spawn, work, return summary, die. They\nhave no identity, no memory between invocations, and no way to receive\nfollow-up instructions. Background tasks (s08) run shell commands but\ncannot make LLM-guided decisions or communicate findings.\n\nFor real teamwork you need three things: (1) persistent agents that\nsurvive beyond a single prompt, (2) identity and lifecycle management,\nand (3) a communication channel between agents. Without messaging, even\npersistent teammates are deaf and mute -- they can work in parallel but\nnever coordinate.\n\nThe solution combines a TeammateManager for spawning persistent named\nagents with a MessageBus using JSONL inbox files. Each teammate runs\nits own agent loop in a thread, checks its inbox before every LLM call,\nand can send messages to any other teammate or the lead.\n\nNote on the s06-to-s07 bridge: TodoManager items from s03 die with\ncompression (s06). File-based tasks (s07) survive compression because\nthey live on disk. Teams build on this same principle -- config.json and\ninbox files persist outside the context window.\n\n## The Solution\n\n```\nTeammate lifecycle:\n  spawn -> WORKING -> IDLE -> WORKING -> ... -> SHUTDOWN\n\nCommunication:\n  .team/\n    config.json           <- team roster + statuses\n    inbox/\n      alice.jsonl         <- append-only, drain-on-read\n      bob.jsonl\n      lead.jsonl\n\n                +--------+    send(\"alice\",\"bob\",\"...\")    +--------+\n                | alice  | -----------------------------> |  bob   |\n                | loop   |    bob.jsonl << {json_line}    |  loop  |\n                +--------+                                +--------+\n                     ^                                         |\n                     |        BUS.read_inbox(\"alice\")          |\n                     +---- alice.jsonl -> read + drain ---------+\n\n5 message types:\n+-------------------------+------------------------------+\n| message                 | Normal text between agents   |\n| broadcast               | Sent to all teammates        |\n| shutdown_request        | Request graceful shutdown     |\n| shutdown_response       | Approve/reject shutdown      |\n| plan_approval_response  | Approve/reject plan          |\n+-------------------------+------------------------------+\n```\n\n## How It Works\n\n1. The TeammateManager maintains config.json with the team roster.\n   Each member has a name, role, and status.\n\n```python\nclass TeammateManager:\n    def __init__(self, team_dir: Path):\n        self.dir = team_dir\n        self.dir.mkdir(exist_ok=True)\n        self.config_path = self.dir / \"config.json\"\n        self.config = self._load_config()\n        self.threads = {}\n```\n\n2. `spawn()` creates a teammate and starts its agent loop in a thread.\n   Re-spawning an idle teammate reactivates it.\n\n```python\ndef spawn(self, name: str, role: str, prompt: str) -> str:\n    member = self._find_member(name)\n    if member:\n        if member[\"status\"] not in (\"idle\", \"shutdown\"):\n            return f\"Error: '{name}' is currently {member['status']}\"\n        member[\"status\"] = \"working\"\n    else:\n        member = {\"name\": name, \"role\": role, \"status\": \"working\"}\n        self.config[\"members\"].append(member)\n    self._save_config()\n    thread = threading.Thread(\n        target=self._teammate_loop,\n        args=(name, role, prompt), daemon=True)\n    self.threads[name] = thread\n    thread.start()\n    return f\"Spawned teammate '{name}' (role: {role})\"\n```\n\n3. The MessageBus handles JSONL inbox files. `send()` appends a JSON\n   line; `read_inbox()` reads all lines and drains the file.\n\n```python\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content,\n               \"timestamp\": time.time()}\n        if extra:\n            msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n        return f\"Sent {msg_type} to {to}\"\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists():\n            return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")  # drain\n        return json.dumps(msgs, indent=2)\n```\n\n4. Each teammate checks its inbox before every LLM call and injects\n   received messages into the conversation context.\n\n```python\ndef _teammate_loop(self, name, role, prompt):\n    sys_prompt = f\"You are '{name}', role: {role}, at {WORKDIR}.\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(50):\n        inbox = BUS.read_inbox(name)\n        if inbox != \"[]\":\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted inbox messages.\"})\n        response = client.messages.create(\n            model=MODEL, system=sys_prompt,\n            messages=messages, tools=TOOLS)\n        messages.append({\"role\": \"assistant\",\n                         \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n    self._find_member(name)[\"status\"] = \"idle\"\n    self._save_config()\n```\n\n5. `broadcast()` sends the same message to all teammates except the\n   sender.\n\n```python\ndef broadcast(self, sender, content, teammates):\n    count = 0\n    for name in teammates:\n        if name != sender:\n            self.send(sender, name, content, \"broadcast\")\n            count += 1\n    return f\"Broadcast to {count} teammates\"\n```\n\n## Key Code\n\nThe TeammateManager + MessageBus core (from `agents/s09_team_messaging.py`):\n\n```python\nclass TeammateManager:\n    def spawn(self, name, role, prompt):\n        member = self._find_member(name) or {\n            \"name\": name, \"role\": role, \"status\": \"working\"\n        }\n        member[\"status\"] = \"working\"\n        self._save_config()\n        thread = threading.Thread(\n            target=self._teammate_loop,\n            args=(name, role, prompt), daemon=True)\n        thread.start()\n        return f\"Spawned '{name}'\"\n\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content, \"timestamp\": time.time()}\n        if extra: msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists(): return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")\n        return json.dumps(msgs, indent=2)\n```\n\n## What Changed From s08\n\n| Component      | Before (s08)     | After (s09)                |\n|----------------|------------------|----------------------------|\n| Tools          | 6                | 9 (+spawn/send/read_inbox) |\n| Agents         | Single           | Lead + N teammates         |\n| Persistence    | None             | config.json + JSONL inboxes|\n| Threads        | Background cmds  | Full agent loops per thread|\n| Lifecycle      | Fire-and-forget  | idle -> working -> idle    |\n| Communication  | None             | 5 message types + broadcast|\n\nTeaching simplification: this implementation does not use lock files\nfor inbox access. In production, concurrent append from multiple writers\nwould need file locking or atomic rename. The single-writer-per-inbox\npattern used here is safe for the teaching scenario.\n\n## Production Reference\n\nClaude Code implements teammate management through the TeammateManager\nand messaging through the SendMessage tool with JSONL inbox files. The\nproduction system supports the same 5 message types and uses the same\nappend/drain pattern. Messages are delivered asynchronously -- the\nsender does not block waiting for the recipient to read. The inbox\ncheck before each LLM call ensures messages arrive at a natural\nbreakpoint. Production adds message deduplication, size limits, and\nproper file locking.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s09_team_messaging.py\n```\n\nExample prompts to try:\n\n1. `Spawn alice (coder) and bob (tester). Have alice send bob a message.`\n2. `Broadcast \"status update: phase 1 complete\" to all teammates`\n3. `Check the lead inbox for any messages`\n4. Type `/team` to see the team roster with statuses\n5. Type `/inbox` to manually check the lead's inbox\n"
  },
  {
    "version": "s10",
    "locale": "ja",
    "title": "s10: Team Protocols",
    "content": "# s10: Team Protocols\n\n> 同じrequest_idハンドシェイクパターンがシャットダウンとプラン承認の両方を支える -- 1つのFSM、2つの適用。\n\n## 問題\n\ns09ではチームメイトが作業しコミュニケーションするが、構造化された協調はない。2つの問題が生じる:\n\n**シャットダウン**: チームメイトをどうやってクリーンに停止するか。スレッドを強制終了するとファイルが中途半端に書かれ、config.jsonが不正な状態になる。グレースフルシャットダウンにはハンドシェイクが必要だ: リーダーが要求し、チームメイトが承認(終了処理を行い退出)するか拒否(作業を継続)するかを判断する。\n\n**プラン承認**: 実行をどうやってゲーティングするか。リーダーが「認証モジュールをリファクタリングして」と言うと、チームメイトは即座に開始する。リスクの高い変更では、実行開始前にリーダーが計画をレビューすべきだ。ジュニアが提案し、シニアが承認する。\n\n両方の問題は同じ構造を共有している: 一方がユニークなIDを持つリクエストを送り、もう一方がそのIDを参照してレスポンスする。有限状態機械が各リクエストをpending -> approved | rejectedの遷移で追跡する。\n\n## 解決策\n\n```\nShutdown Protocol            Plan Approval Protocol\n==================           ======================\n\nLead             Teammate    Teammate           Lead\n  |                 |           |                 |\n  |--shutdown_req-->|           |--plan_req------>|\n  | {req_id:\"abc\"}  |           | {req_id:\"xyz\"}  |\n  |                 |           |                 |\n  |<--shutdown_resp-|           |<--plan_resp-----|\n  | {req_id:\"abc\",  |           | {req_id:\"xyz\",  |\n  |  approve:true}  |           |  approve:true}  |\n  |                 |           |                 |\n  v                 v           v                 v\ntracker[\"abc\"]     exits     proceeds          tracker[\"xyz\"]\n = approved                                     = approved\n\nShared FSM (identical for both protocols):\n  [pending] --approve--> [approved]\n  [pending] --reject---> [rejected]\n\nTrackers:\n  shutdown_requests = {req_id: {target, status}}\n  plan_requests     = {req_id: {from, plan, status}}\n```\n\n## 仕組み\n\n1. リーダーがrequest_idを生成し、インボックス経由でshutdown_requestを送信してシャットダウンを開始する。\n\n```python\nshutdown_requests = {}\n\ndef handle_shutdown_request(teammate: str) -> str:\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\",\n    }\n    BUS.send(\"lead\", teammate, \"Please shut down gracefully.\",\n             \"shutdown_request\", {\"request_id\": req_id})\n    return f\"Shutdown request {req_id} sent (status: pending)\"\n```\n\n2. チームメイトはインボックスでリクエストを受信し、`shutdown_response`ツールを呼び出して承認または拒否する。\n\n```python\nif tool_name == \"shutdown_response\":\n    req_id = args[\"request_id\"]\n    approve = args[\"approve\"]\n    if req_id in shutdown_requests:\n        shutdown_requests[req_id][\"status\"] = \\\n            \"approved\" if approve else \"rejected\"\n    BUS.send(sender, \"lead\", args.get(\"reason\", \"\"),\n             \"shutdown_response\",\n             {\"request_id\": req_id, \"approve\": approve})\n    return f\"Shutdown {'approved' if approve else 'rejected'}\"\n```\n\n3. チームメイトのループが承認済みシャットダウンを確認して終了する。\n\n```python\nif (block.name == \"shutdown_response\"\n        and block.input.get(\"approve\")):\n    should_exit = True\n# ...\nmember[\"status\"] = \"shutdown\" if should_exit else \"idle\"\n```\n\n4. プラン承認も同一のパターンに従う。チームメイトがプランを提出し、request_idを生成する。\n\n```python\nplan_requests = {}\n\nif tool_name == \"plan_approval\":\n    plan_text = args.get(\"plan\", \"\")\n    req_id = str(uuid.uuid4())[:8]\n    plan_requests[req_id] = {\n        \"from\": sender, \"plan\": plan_text,\n        \"status\": \"pending\",\n    }\n    BUS.send(sender, \"lead\", plan_text,\n             \"plan_approval_request\",\n             {\"request_id\": req_id, \"plan\": plan_text})\n    return f\"Plan submitted (request_id={req_id})\"\n```\n\n5. リーダーがレビューし、同じrequest_idでレスポンスする。\n\n```python\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests.get(request_id)\n    if not req:\n        return f\"Error: Unknown request_id '{request_id}'\"\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve,\n              \"feedback\": feedback})\n    return f\"Plan {req['status']} for '{req['from']}'\"\n```\n\n6. 両プロトコルとも同じ`plan_approval`ツール名を2つのモードで使用する: チームメイトが提出(request_idなし)、リーダーがレビュー(request_idあり)。\n\n```python\n# Lead tool dispatch:\n\"plan_approval\": lambda **kw: handle_plan_review(\n    kw[\"request_id\"], kw[\"approve\"],\n    kw.get(\"feedback\", \"\")),\n# Teammate: submit mode (generate request_id)\n```\n\n## 主要コード\n\n2つのプロトコルハンドラ(`agents/s10_team_protocols.py`):\n\n```python\nshutdown_requests = {}\nplan_requests = {}\n\n# -- Shutdown --\ndef handle_shutdown_request(teammate):\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\"\n    }\n    BUS.send(\"lead\", teammate,\n             \"Please shut down gracefully.\",\n             \"shutdown_request\",\n             {\"request_id\": req_id})\n\n# -- Plan Approval --\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests[request_id]\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve})\n\n# Both use the same FSM:\n# pending -> approved | rejected\n# Both correlate by request_id across async inboxes\n```\n\n## s09からの変更点\n\n| Component      | Before (s09)     | After (s10)                  |\n|----------------|------------------|------------------------------|\n| Tools          | 9                | 12 (+shutdown_req/resp +plan)|\n| Shutdown       | Natural exit only| Request-response handshake   |\n| Plan gating    | None             | Submit/review with approval  |\n| Request tracking| None            | Two tracker dicts            |\n| Correlation    | None             | request_id per request       |\n| FSM            | None             | pending -> approved/rejected |\n\n## 本番環境との対応\n\nClaude CodeではSendMessageツールの`type: \"shutdown_request\"`によるシャットダウンとExitPlanModeによるプラン承認を実装している。チームメイトが`plan_mode_required`を設定されている場合、実行前にプランを提出しなければならない。本番バージョンではシャットダウンのタイムアウト処理(設定可能なウィンドウ後の強制終了)とプラン修正(拒否されたプランは修正して再提出可能)が追加されている。request_idパターンは任意の非同期承認ワークフローに一般化できる -- 何が承認されるかに関わらず同じFSMが適用される。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s10_team_protocols.py\n```\n\n試せるプロンプト例:\n\n1. `Spawn alice as a coder. Then request her shutdown.`\n2. `List teammates to see alice's status after shutdown approval`\n3. `Spawn bob with a risky refactoring task. Review and reject his plan.`\n4. `Spawn charlie, have him submit a plan, then approve it.`\n5. `/team`と入力してステータスを監視する\n"
  },
  {
    "version": "s10",
    "locale": "zh",
    "title": "s10: Team Protocols (团队协议)",
    "content": "# s10: Team Protocols (团队协议)\n\n> 同一个 request_id 握手模式驱动了关机和计划审批两种协议 -- 一个 FSM, 两种应用。\n\n## 问题\n\n在 s09 中, 队友可以工作和通信, 但没有结构化的协调。出现了两个问题:\n\n**关机**: 如何干净地停止一个队友? 直接杀线程会留下写了一半的文件和错误状态的 config.json。优雅关机需要握手: 领导发起请求, 队友决定是批准 (完成并退出) 还是拒绝 (继续工作)。\n\n**计划审批**: 如何控制执行门槛? 当领导说 \"重构认证模块\", 队友会立即开始。对于高风险变更, 领导应该在执行开始前审查计划。初级提出方案, 高级批准。\n\n两个问题共享相同的结构: 一方发送带唯一 ID 的请求, 另一方引用该 ID 作出响应。一个有限状态机 (FSM) 跟踪每个请求经历 pending -> approved | rejected 的状态变迁。\n\n## 解决方案\n\n```\nShutdown Protocol            Plan Approval Protocol\n==================           ======================\n\nLead             Teammate    Teammate           Lead\n  |                 |           |                 |\n  |--shutdown_req-->|           |--plan_req------>|\n  | {req_id:\"abc\"}  |           | {req_id:\"xyz\"}  |\n  |                 |           |                 |\n  |<--shutdown_resp-|           |<--plan_resp-----|\n  | {req_id:\"abc\",  |           | {req_id:\"xyz\",  |\n  |  approve:true}  |           |  approve:true}  |\n  |                 |           |                 |\n  v                 v           v                 v\ntracker[\"abc\"]     exits     proceeds          tracker[\"xyz\"]\n = approved                                     = approved\n\nShared FSM (identical for both protocols):\n  [pending] --approve--> [approved]\n  [pending] --reject---> [rejected]\n\nTrackers:\n  shutdown_requests = {req_id: {target, status}}\n  plan_requests     = {req_id: {from, plan, status}}\n```\n\n## 工作原理\n\n1. 领导通过生成 request_id 并通过收件箱发送 shutdown_request 来发起关机。\n\n```python\nshutdown_requests = {}\n\ndef handle_shutdown_request(teammate: str) -> str:\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\",\n    }\n    BUS.send(\"lead\", teammate, \"Please shut down gracefully.\",\n             \"shutdown_request\", {\"request_id\": req_id})\n    return f\"Shutdown request {req_id} sent (status: pending)\"\n```\n\n2. 队友在收件箱中收到请求, 调用 `shutdown_response` 工具来批准或拒绝。\n\n```python\nif tool_name == \"shutdown_response\":\n    req_id = args[\"request_id\"]\n    approve = args[\"approve\"]\n    if req_id in shutdown_requests:\n        shutdown_requests[req_id][\"status\"] = \\\n            \"approved\" if approve else \"rejected\"\n    BUS.send(sender, \"lead\", args.get(\"reason\", \"\"),\n             \"shutdown_response\",\n             {\"request_id\": req_id, \"approve\": approve})\n    return f\"Shutdown {'approved' if approve else 'rejected'}\"\n```\n\n3. 队友的循环检查是否批准了关机并退出。\n\n```python\nif (block.name == \"shutdown_response\"\n        and block.input.get(\"approve\")):\n    should_exit = True\n# ...\nmember[\"status\"] = \"shutdown\" if should_exit else \"idle\"\n```\n\n4. 计划审批遵循完全相同的模式。队友提交计划时生成一个 request_id。\n\n```python\nplan_requests = {}\n\nif tool_name == \"plan_approval\":\n    plan_text = args.get(\"plan\", \"\")\n    req_id = str(uuid.uuid4())[:8]\n    plan_requests[req_id] = {\n        \"from\": sender, \"plan\": plan_text,\n        \"status\": \"pending\",\n    }\n    BUS.send(sender, \"lead\", plan_text,\n             \"plan_approval_request\",\n             {\"request_id\": req_id, \"plan\": plan_text})\n    return f\"Plan submitted (request_id={req_id})\"\n```\n\n5. 领导审查后使用同一个 request_id 作出响应。\n\n```python\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests.get(request_id)\n    if not req:\n        return f\"Error: Unknown request_id '{request_id}'\"\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve,\n              \"feedback\": feedback})\n    return f\"Plan {req['status']} for '{req['from']}'\"\n```\n\n6. 两个协议使用同一个 `plan_approval` 工具名, 有两种模式: 队友提交 (无 request_id), 领导审查 (带 request_id)。\n\n```python\n# Lead tool dispatch:\n\"plan_approval\": lambda **kw: handle_plan_review(\n    kw[\"request_id\"], kw[\"approve\"],\n    kw.get(\"feedback\", \"\")),\n# Teammate: submit mode (generate request_id)\n```\n\n## 核心代码\n\n双协议处理器 (来自 `agents/s10_team_protocols.py`):\n\n```python\nshutdown_requests = {}\nplan_requests = {}\n\n# -- Shutdown --\ndef handle_shutdown_request(teammate):\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\"\n    }\n    BUS.send(\"lead\", teammate,\n             \"Please shut down gracefully.\",\n             \"shutdown_request\",\n             {\"request_id\": req_id})\n\n# -- Plan Approval --\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests[request_id]\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve})\n\n# Both use the same FSM:\n# pending -> approved | rejected\n# Both correlate by request_id across async inboxes\n```\n\n## 相对 s09 的变更\n\n| 组件           | 之前 (s09)       | 之后 (s10)                           |\n|----------------|------------------|--------------------------------------|\n| Tools          | 9                | 12 (+shutdown_req/resp +plan)        |\n| 关机           | 仅自然退出       | 请求-响应握手                        |\n| 计划门控       | 无               | 提交/审查与审批                      |\n| 请求追踪       | 无               | 两个 tracker 字典                    |\n| 关联           | 无               | 每个请求一个 request_id              |\n| FSM            | 无               | pending -> approved/rejected         |\n\n## 生产环境参考\n\nClaude Code 通过 SendMessage 工具的 `type: \"shutdown_request\"` 实现关机, 通过 ExitPlanMode 实现计划审批。当队友设置了 `plan_mode_required` 时, 必须先提交计划才能执行。生产版本增加了关机超时处理 (可配置时间窗口后强制终止) 和计划修订 (被拒绝的计划可以修改后重新提交)。request_id 模式可推广到任何异步审批工作流 -- 无论审批什么, 同一个 FSM 都适用。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s10_team_protocols.py\n```\n\n可以尝试的提示:\n\n1. `Spawn alice as a coder. Then request her shutdown.`\n2. `List teammates to see alice's status after shutdown approval`\n3. `Spawn bob with a risky refactoring task. Review and reject his plan.`\n4. `Spawn charlie, have him submit a plan, then approve it.`\n5. 输入 `/team` 监控状态\n"
  },
  {
    "version": "s10",
    "locale": "en",
    "title": "s10: Team Protocols",
    "content": "# s10: Team Protocols\n\n> The same request_id handshake pattern powers both shutdown and plan approval -- one FSM, two applications.\n\n## The Problem\n\nIn s09, teammates work and communicate but there is no structured\ncoordination. Two problems arise:\n\n**Shutdown**: How do you stop a teammate cleanly? Killing the thread\nleaves files partially written and config.json in a wrong state.\nGraceful shutdown requires a handshake: the lead requests, the teammate\ndecides whether to approve (finish and exit) or reject (keep working).\n\n**Plan approval**: How do you gate execution? When the lead says\n\"refactor the auth module,\" the teammate starts immediately. For\nhigh-risk changes, the lead should review the plan before execution\nbegins. A junior proposes, a senior approves.\n\nBoth problems share the same structure: one side sends a request with a\nunique ID, the other side responds referencing that ID. A finite state\nmachine tracks each request through pending -> approved | rejected.\n\n## The Solution\n\n```\nShutdown Protocol            Plan Approval Protocol\n==================           ======================\n\nLead             Teammate    Teammate           Lead\n  |                 |           |                 |\n  |--shutdown_req-->|           |--plan_req------>|\n  | {req_id:\"abc\"}  |           | {req_id:\"xyz\"}  |\n  |                 |           |                 |\n  |<--shutdown_resp-|           |<--plan_resp-----|\n  | {req_id:\"abc\",  |           | {req_id:\"xyz\",  |\n  |  approve:true}  |           |  approve:true}  |\n  |                 |           |                 |\n  v                 v           v                 v\ntracker[\"abc\"]     exits     proceeds          tracker[\"xyz\"]\n = approved                                     = approved\n\nShared FSM (identical for both protocols):\n  [pending] --approve--> [approved]\n  [pending] --reject---> [rejected]\n\nTrackers:\n  shutdown_requests = {req_id: {target, status}}\n  plan_requests     = {req_id: {from, plan, status}}\n```\n\n## How It Works\n\n1. The lead initiates shutdown by generating a request_id and sending\n   a shutdown_request through the inbox.\n\n```python\nshutdown_requests = {}\n\ndef handle_shutdown_request(teammate: str) -> str:\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\",\n    }\n    BUS.send(\"lead\", teammate, \"Please shut down gracefully.\",\n             \"shutdown_request\", {\"request_id\": req_id})\n    return f\"Shutdown request {req_id} sent (status: pending)\"\n```\n\n2. The teammate receives the request in its inbox and calls the\n   `shutdown_response` tool to approve or reject.\n\n```python\nif tool_name == \"shutdown_response\":\n    req_id = args[\"request_id\"]\n    approve = args[\"approve\"]\n    if req_id in shutdown_requests:\n        shutdown_requests[req_id][\"status\"] = \\\n            \"approved\" if approve else \"rejected\"\n    BUS.send(sender, \"lead\", args.get(\"reason\", \"\"),\n             \"shutdown_response\",\n             {\"request_id\": req_id, \"approve\": approve})\n    return f\"Shutdown {'approved' if approve else 'rejected'}\"\n```\n\n3. The teammate loop checks for approved shutdown and exits.\n\n```python\nif (block.name == \"shutdown_response\"\n        and block.input.get(\"approve\")):\n    should_exit = True\n# ...\nmember[\"status\"] = \"shutdown\" if should_exit else \"idle\"\n```\n\n4. Plan approval follows the identical pattern. The teammate submits\n   a plan, generating a request_id.\n\n```python\nplan_requests = {}\n\nif tool_name == \"plan_approval\":\n    plan_text = args.get(\"plan\", \"\")\n    req_id = str(uuid.uuid4())[:8]\n    plan_requests[req_id] = {\n        \"from\": sender, \"plan\": plan_text,\n        \"status\": \"pending\",\n    }\n    BUS.send(sender, \"lead\", plan_text,\n             \"plan_approval_request\",\n             {\"request_id\": req_id, \"plan\": plan_text})\n    return f\"Plan submitted (request_id={req_id})\"\n```\n\n5. The lead reviews and responds with the same request_id.\n\n```python\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests.get(request_id)\n    if not req:\n        return f\"Error: Unknown request_id '{request_id}'\"\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve,\n              \"feedback\": feedback})\n    return f\"Plan {req['status']} for '{req['from']}'\"\n```\n\n6. Both protocols use the same `plan_approval` tool name with two\n   modes: teammates submit (no request_id), the lead reviews (with\n   request_id).\n\n```python\n# Lead tool dispatch:\n\"plan_approval\": lambda **kw: handle_plan_review(\n    kw[\"request_id\"], kw[\"approve\"],\n    kw.get(\"feedback\", \"\")),\n# Teammate: submit mode (generate request_id)\n```\n\n## Key Code\n\nThe dual protocol handlers (from `agents/s10_team_protocols.py`):\n\n```python\nshutdown_requests = {}\nplan_requests = {}\n\n# -- Shutdown --\ndef handle_shutdown_request(teammate):\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\"\n    }\n    BUS.send(\"lead\", teammate,\n             \"Please shut down gracefully.\",\n             \"shutdown_request\",\n             {\"request_id\": req_id})\n\n# -- Plan Approval --\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests[request_id]\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve})\n\n# Both use the same FSM:\n# pending -> approved | rejected\n# Both correlate by request_id across async inboxes\n```\n\n## What Changed From s09\n\n| Component      | Before (s09)     | After (s10)                  |\n|----------------|------------------|------------------------------|\n| Tools          | 9                | 12 (+shutdown_req/resp +plan)|\n| Shutdown       | Natural exit only| Request-response handshake   |\n| Plan gating    | None             | Submit/review with approval  |\n| Request tracking| None            | Two tracker dicts            |\n| Correlation    | None             | request_id per request       |\n| FSM            | None             | pending -> approved/rejected |\n\n## Production Reference\n\nClaude Code implements shutdown through the SendMessage tool with\n`type: \"shutdown_request\"` and plan approval through ExitPlanMode.\nWhen a teammate has `plan_mode_required` set, it must submit a plan\nbefore executing. The production version adds timeout handling for\nshutdown (force-kill after configurable window) and plan revisions\n(rejected plans can be modified and resubmitted). The request_id\npattern generalizes to any async approval workflow -- the same FSM\napplies regardless of what is being approved.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s10_team_protocols.py\n```\n\nExample prompts to try:\n\n1. `Spawn alice as a coder. Then request her shutdown.`\n2. `List teammates to see alice's status after shutdown approval`\n3. `Spawn bob with a risky refactoring task. Review and reject his plan.`\n4. `Spawn charlie, have him submit a plan, then approve it.`\n5. Type `/team` to monitor statuses\n"
  },
  {
    "version": "s11",
    "locale": "ja",
    "title": "s11: Autonomous Agents",
    "content": "# s11: Autonomous Agents\n\n> タスクボードポーリング付きのアイドルサイクルにより、チームメイトが自分で作業を見つけて確保できるようになり、コンテキスト圧縮後にはアイデンティティの再注入が行われる。\n\n## 問題\n\ns09-s10では、チームメイトは明示的に指示された時のみ作業する。リーダーは各チームメイトを特定のプロンプトでspawnしなければならない。タスクボードに未割り当てのタスクが10個あっても、リーダーが手動で各タスクを割り当てなければならない。これはスケールしない。\n\n真の自律性とは、チームメイトが自分で作業を見つけることだ。チームメイトが現在のタスクを完了したら、タスクボードで未確保の作業をスキャンし、タスクを確保し、作業を開始すべきだ -- リーダーからの指示なしに。\n\nしかし自律エージェントには微妙な問題がある: コンテキスト圧縮後に、エージェントが自分が誰かを忘れる可能性がある。メッセージが要約されると、元のシステムプロンプトのアイデンティティ(「あなたはalice、役割はcoder」)が薄れる。アイデンティティの再注入は、圧縮されたコンテキストの先頭にアイデンティティブロックを挿入することでこれを解決する。\n\n教育上の簡略化: ここで使用するトークン推定は大まかなもの(文字数 / 4)だ。本番システムでは適切なトークナイザーライブラリを使用する。nagの閾値3ラウンド(s03から)は教育目的の可視化のために低く設定されている。本番のClaude Codeでは閾値は約10。\n\n## 解決策\n\n```\nTeammate lifecycle with idle cycle:\n\n+-------+\n| spawn |\n+---+---+\n    |\n    v\n+-------+   tool_use     +-------+\n| WORK  | <------------- |  LLM  |\n+---+---+                +-------+\n    |\n    | stop_reason != tool_use\n    | (or idle tool called)\n    v\n+--------+\n|  IDLE  |  poll every 5s for up to 60s\n+---+----+\n    |\n    +---> check inbox --> message? ----------> WORK\n    |\n    +---> scan .tasks/ --> unclaimed? -------> claim -> WORK\n    |\n    +---> 60s timeout ----------------------> SHUTDOWN\n\nIdentity re-injection after compression:\n  if len(messages) <= 3:\n    messages.insert(0, identity_block)\n    \"You are 'alice', role: coder, team: my-team\"\n```\n\n## 仕組み\n\n1. チームメイトのループにはWORKとIDLEの2つのフェーズがある。WORKは標準的なagent loopを実行する。LLMがツール呼び出しを停止した時(または`idle`ツールを呼び出した時)、チームメイトはIDLEフェーズに入る。\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # -- WORK PHASE --\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        for _ in range(50):\n            inbox = BUS.read_inbox(name)\n            for msg in inbox:\n                if msg.get(\"type\") == \"shutdown_request\":\n                    self._set_status(name, \"shutdown\")\n                    return\n                messages.append(...)\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            # execute tools...\n            if idle_requested:\n                break\n\n        # -- IDLE PHASE --\n        self._set_status(name, \"idle\")\n        resume = self._idle_poll(name, messages)\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n2. IDLEフェーズがインボックスとタスクボードをループでポーリングする。\n\n```python\ndef _idle_poll(self, name, messages):\n    polls = IDLE_TIMEOUT // POLL_INTERVAL  # 60s / 5s = 12\n    for _ in range(polls):\n        time.sleep(POLL_INTERVAL)\n        # Check inbox for new messages\n        inbox = BUS.read_inbox(name)\n        if inbox:\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            return True\n        # Scan task board for unclaimed tasks\n        unclaimed = scan_unclaimed_tasks()\n        if unclaimed:\n            task = unclaimed[0]\n            claim_task(task[\"id\"], name)\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<auto-claimed>Task #{task['id']}: \"\n                           f\"{task['subject']}</auto-claimed>\"})\n            return True\n    return False  # timeout -> shutdown\n```\n\n3. タスクボードスキャンがpendingかつ未割り当てかつブロックされていないタスクを探す。\n\n```python\ndef scan_unclaimed_tasks() -> list:\n    TASKS_DIR.mkdir(exist_ok=True)\n    unclaimed = []\n    for f in sorted(TASKS_DIR.glob(\"task_*.json\")):\n        task = json.loads(f.read_text())\n        if (task.get(\"status\") == \"pending\"\n                and not task.get(\"owner\")\n                and not task.get(\"blockedBy\")):\n            unclaimed.append(task)\n    return unclaimed\n\ndef claim_task(task_id: int, owner: str):\n    path = TASKS_DIR / f\"task_{task_id}.json\"\n    task = json.loads(path.read_text())\n    task[\"status\"] = \"in_progress\"\n    task[\"owner\"] = owner\n    path.write_text(json.dumps(task, indent=2))\n```\n\n4. アイデンティティの再注入は、コンテキストが短すぎる場合(圧縮が発生したことを示す)にアイデンティティブロックを挿入する。\n\n```python\ndef make_identity_block(name, role, team_name):\n    return {\"role\": \"user\",\n            \"content\": f\"<identity>You are '{name}', \"\n                       f\"role: {role}, team: {team_name}. \"\n                       f\"Continue your work.</identity>\"}\n\n# Before resuming work after idle:\nif len(messages) <= 3:\n    messages.insert(0, make_identity_block(\n        name, role, team_name))\n    messages.insert(1, {\"role\": \"assistant\",\n        \"content\": f\"I am {name}. Continuing.\"})\n```\n\n5. `idle`ツールにより、チームメイトはもう作業がないことを明示的にシグナルし、早期にアイドルポーリングフェーズに入る。\n\n```python\n{\"name\": \"idle\",\n \"description\": \"Signal that you have no more work. \"\n                \"Enters idle polling phase.\",\n \"input_schema\": {\"type\": \"object\", \"properties\": {}}},\n```\n\n## 主要コード\n\n自律ループ(`agents/s11_autonomous.py`):\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # WORK PHASE\n        for _ in range(50):\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            for block in response.content:\n                if block.name == \"idle\":\n                    idle_requested = True\n            if idle_requested:\n                break\n\n        # IDLE PHASE\n        self._set_status(name, \"idle\")\n        for _ in range(IDLE_TIMEOUT // POLL_INTERVAL):\n            time.sleep(POLL_INTERVAL)\n            inbox = BUS.read_inbox(name)\n            if inbox: resume = True; break\n            unclaimed = scan_unclaimed_tasks()\n            if unclaimed:\n                claim_task(unclaimed[0][\"id\"], name)\n                resume = True; break\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n## s10からの変更点\n\n| Component      | Before (s10)     | After (s11)                |\n|----------------|------------------|----------------------------|\n| Tools          | 12               | 14 (+idle, +claim_task)    |\n| Autonomy       | Lead-directed    | Self-organizing            |\n| Idle phase     | None             | Poll inbox + task board    |\n| Task claiming  | Manual only      | Auto-claim unclaimed tasks |\n| Identity       | System prompt    | + re-injection after compress|\n| Timeout        | None             | 60s idle -> auto shutdown  |\n\n## 本番環境との対応\n\nClaude Codeは同じidle/poll/claimサイクルで自律的なチームメイトを実装している。本番バージョンではステータス変更にTaskUpdateツールを使用し、アイドル通知システムを備えている。チームメイトはタスクボードから自動的に作業を発見し、リーダーの介入なしに確保する。アイデンティティの再注入により、圧縮後もチームメイトは自身の役割とコンテキストを維持する。本番のアイドルタイムアウトはチームメイトごとに設定可能だ。重要な洞察: リーダーがタスクボードを作成し、チームメイトが自己組織化してそれを完了する。\n\n## 試してみる\n\n```sh\ncd learn-claude-code\npython agents/s11_autonomous.py\n```\n\n試せるプロンプト例:\n\n1. `Create 3 tasks on the board, then spawn alice and bob. Watch them auto-claim.`\n2. `Spawn a coder teammate and let it find work from the task board itself`\n3. `Create tasks with dependencies. Watch teammates respect the blocked order.`\n4. `/tasks`と入力してオーナー付きのタスクボードを確認する\n5. `/team`と入力して誰が作業中でアイドルかを監視する\n"
  },
  {
    "version": "s11",
    "locale": "zh",
    "title": "s11: Autonomous Agents (自治智能体)",
    "content": "# s11: Autonomous Agents (自治智能体)\n\n> 带任务看板轮询的空闲循环让队友能自己发现和认领工作, 上下文压缩后通过身份重注入保持角色认知。\n\n## 问题\n\n在 s09-s10 中, 队友只在被明确指示时才工作。领导必须用特定的 prompt 生成每个队友。如果任务看板上有 10 个未认领的任务, 领导必须手动分配每一个。这无法扩展。\n\n真正的自治意味着队友自己寻找工作。当一个队友完成当前任务后, 它应该扫描任务看板寻找未认领的工作, 认领一个任务, 然后开始工作 -- 不需要领导的任何指令。\n\n但自治智能体面临一个微妙问题: 上下文压缩后, 智能体可能忘记自己是谁。如果消息被摘要化, 原始系统提示中的身份 (\"你是 alice, 角色: coder\") 就会淡化。身份重注入通过在压缩后的上下文开头插入身份块来解决这个问题。\n\n教学简化说明: 这里的 token 估算比较粗糙 (字符数 / 4)。生产系统使用专业的 tokenizer 库。s03 中的 nag 阈值 3 轮是为教学可见性设的低值; 生产环境的 Claude Code 使用约 10 轮的阈值。\n\n## 解决方案\n\n```\nTeammate lifecycle with idle cycle:\n\n+-------+\n| spawn |\n+---+---+\n    |\n    v\n+-------+   tool_use     +-------+\n| WORK  | <------------- |  LLM  |\n+---+---+                +-------+\n    |\n    | stop_reason != tool_use\n    | (or idle tool called)\n    v\n+--------+\n|  IDLE  |  poll every 5s for up to 60s\n+---+----+\n    |\n    +---> check inbox --> message? ----------> WORK\n    |\n    +---> scan .tasks/ --> unclaimed? -------> claim -> WORK\n    |\n    +---> 60s timeout ----------------------> SHUTDOWN\n\nIdentity re-injection after compression:\n  if len(messages) <= 3:\n    messages.insert(0, identity_block)\n    \"You are 'alice', role: coder, team: my-team\"\n```\n\n## 工作原理\n\n1. 队友循环有两个阶段: WORK 和 IDLE。WORK 阶段运行标准的 agent loop。当 LLM 停止调用工具 (或调用了 `idle` 工具) 时, 队友进入 IDLE 阶段。\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # -- WORK PHASE --\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        for _ in range(50):\n            inbox = BUS.read_inbox(name)\n            for msg in inbox:\n                if msg.get(\"type\") == \"shutdown_request\":\n                    self._set_status(name, \"shutdown\")\n                    return\n                messages.append(...)\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            # execute tools...\n            if idle_requested:\n                break\n\n        # -- IDLE PHASE --\n        self._set_status(name, \"idle\")\n        resume = self._idle_poll(name, messages)\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n2. 空闲阶段循环轮询收件箱和任务看板。\n\n```python\ndef _idle_poll(self, name, messages):\n    polls = IDLE_TIMEOUT // POLL_INTERVAL  # 60s / 5s = 12\n    for _ in range(polls):\n        time.sleep(POLL_INTERVAL)\n        # Check inbox for new messages\n        inbox = BUS.read_inbox(name)\n        if inbox:\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            return True\n        # Scan task board for unclaimed tasks\n        unclaimed = scan_unclaimed_tasks()\n        if unclaimed:\n            task = unclaimed[0]\n            claim_task(task[\"id\"], name)\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<auto-claimed>Task #{task['id']}: \"\n                           f\"{task['subject']}</auto-claimed>\"})\n            return True\n    return False  # timeout -> shutdown\n```\n\n3. 任务看板扫描查找 pending 状态、无 owner、未被阻塞的任务。\n\n```python\ndef scan_unclaimed_tasks() -> list:\n    TASKS_DIR.mkdir(exist_ok=True)\n    unclaimed = []\n    for f in sorted(TASKS_DIR.glob(\"task_*.json\")):\n        task = json.loads(f.read_text())\n        if (task.get(\"status\") == \"pending\"\n                and not task.get(\"owner\")\n                and not task.get(\"blockedBy\")):\n            unclaimed.append(task)\n    return unclaimed\n\ndef claim_task(task_id: int, owner: str):\n    path = TASKS_DIR / f\"task_{task_id}.json\"\n    task = json.loads(path.read_text())\n    task[\"status\"] = \"in_progress\"\n    task[\"owner\"] = owner\n    path.write_text(json.dumps(task, indent=2))\n```\n\n4. 身份重注入: 当上下文过短时插入身份块, 表明发生了压缩。\n\n```python\ndef make_identity_block(name, role, team_name):\n    return {\"role\": \"user\",\n            \"content\": f\"<identity>You are '{name}', \"\n                       f\"role: {role}, team: {team_name}. \"\n                       f\"Continue your work.</identity>\"}\n\n# Before resuming work after idle:\nif len(messages) <= 3:\n    messages.insert(0, make_identity_block(\n        name, role, team_name))\n    messages.insert(1, {\"role\": \"assistant\",\n        \"content\": f\"I am {name}. Continuing.\"})\n```\n\n5. `idle` 工具让队友显式地表示没有更多工作, 提前进入空闲轮询阶段。\n\n```python\n{\"name\": \"idle\",\n \"description\": \"Signal that you have no more work. \"\n                \"Enters idle polling phase.\",\n \"input_schema\": {\"type\": \"object\", \"properties\": {}}},\n```\n\n## 核心代码\n\n自治循环 (来自 `agents/s11_autonomous.py`):\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # WORK PHASE\n        for _ in range(50):\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            for block in response.content:\n                if block.name == \"idle\":\n                    idle_requested = True\n            if idle_requested:\n                break\n\n        # IDLE PHASE\n        self._set_status(name, \"idle\")\n        for _ in range(IDLE_TIMEOUT // POLL_INTERVAL):\n            time.sleep(POLL_INTERVAL)\n            inbox = BUS.read_inbox(name)\n            if inbox: resume = True; break\n            unclaimed = scan_unclaimed_tasks()\n            if unclaimed:\n                claim_task(unclaimed[0][\"id\"], name)\n                resume = True; break\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n## 相对 s10 的变更\n\n| 组件           | 之前 (s10)       | 之后 (s11)                       |\n|----------------|------------------|----------------------------------|\n| Tools          | 12               | 14 (+idle, +claim_task)          |\n| 自治性         | 领导指派         | 自组织                           |\n| 空闲阶段       | 无               | 轮询收件箱 + 任务看板           |\n| 任务认领       | 仅手动           | 自动认领未认领任务               |\n| 身份           | 系统提示         | + 压缩后重注入                   |\n| 超时           | 无               | 60 秒空闲 -> 自动关机            |\n\n## 生产环境参考\n\nClaude Code 以相同的 idle/poll/claim 循环实现自治队友。生产版本使用 TaskUpdate 工具进行状态变更, 并有空闲通知系统。队友自动从任务看板发现工作并认领, 无需领导干预。身份重注入确保队友在压缩后保持其角色和上下文。生产环境的空闲超时可按队友配置。核心洞察: 领导创建任务看板, 队友自组织完成它。\n\n## 试一试\n\n```sh\ncd learn-claude-code\npython agents/s11_autonomous.py\n```\n\n可以尝试的提示:\n\n1. `Create 3 tasks on the board, then spawn alice and bob. Watch them auto-claim.`\n2. `Spawn a coder teammate and let it find work from the task board itself`\n3. `Create tasks with dependencies. Watch teammates respect the blocked order.`\n4. 输入 `/tasks` 查看带 owner 的任务看板\n5. 输入 `/team` 监控谁在工作、谁在空闲\n"
  },
  {
    "version": "s11",
    "locale": "en",
    "title": "s11: Autonomous Agents",
    "content": "# s11: Autonomous Agents\n\n> An idle cycle with task board polling lets teammates find and claim work themselves, with identity re-injection after context compression.\n\n## The Problem\n\nIn s09-s10, teammates only work when explicitly told to. The lead must\nspawn each teammate with a specific prompt. If the task board has 10\nunclaimed tasks, the lead must manually assign each one. This does not\nscale.\n\nTrue autonomy means teammates find work themselves. When a teammate\nfinishes its current task, it should scan the task board for unclaimed\nwork, claim a task, and start working -- without any instruction from\nthe lead.\n\nBut autonomous agents face a subtlety: after context compression, the\nagent might forget who it is. If the messages are summarized, the\noriginal system prompt identity (\"you are alice, role: coder\") fades.\nIdentity re-injection solves this by inserting an identity block at the\nstart of compressed contexts.\n\nTeaching simplification: the token estimation used here is rough\n(characters / 4). Production systems use proper tokenizer libraries.\nThe nag threshold of 3 rounds (from s03) is set low for teaching\nvisibility; production Claude Code uses a threshold around 10.\n\n## The Solution\n\n```\nTeammate lifecycle with idle cycle:\n\n+-------+\n| spawn |\n+---+---+\n    |\n    v\n+-------+   tool_use     +-------+\n| WORK  | <------------- |  LLM  |\n+---+---+                +-------+\n    |\n    | stop_reason != tool_use\n    | (or idle tool called)\n    v\n+--------+\n|  IDLE  |  poll every 5s for up to 60s\n+---+----+\n    |\n    +---> check inbox --> message? ----------> WORK\n    |\n    +---> scan .tasks/ --> unclaimed? -------> claim -> WORK\n    |\n    +---> 60s timeout ----------------------> SHUTDOWN\n\nIdentity re-injection after compression:\n  if len(messages) <= 3:\n    messages.insert(0, identity_block)\n    \"You are 'alice', role: coder, team: my-team\"\n```\n\n## How It Works\n\n1. The teammate loop has two phases: WORK and IDLE. WORK runs the\n   standard agent loop. When the LLM stops calling tools (or calls\n   the `idle` tool), the teammate enters the IDLE phase.\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # -- WORK PHASE --\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        for _ in range(50):\n            inbox = BUS.read_inbox(name)\n            for msg in inbox:\n                if msg.get(\"type\") == \"shutdown_request\":\n                    self._set_status(name, \"shutdown\")\n                    return\n                messages.append(...)\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            # execute tools...\n            if idle_requested:\n                break\n\n        # -- IDLE PHASE --\n        self._set_status(name, \"idle\")\n        resume = self._idle_poll(name, messages)\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n2. The idle phase polls the inbox and task board in a loop.\n\n```python\ndef _idle_poll(self, name, messages):\n    polls = IDLE_TIMEOUT // POLL_INTERVAL  # 60s / 5s = 12\n    for _ in range(polls):\n        time.sleep(POLL_INTERVAL)\n        # Check inbox for new messages\n        inbox = BUS.read_inbox(name)\n        if inbox:\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            return True\n        # Scan task board for unclaimed tasks\n        unclaimed = scan_unclaimed_tasks()\n        if unclaimed:\n            task = unclaimed[0]\n            claim_task(task[\"id\"], name)\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<auto-claimed>Task #{task['id']}: \"\n                           f\"{task['subject']}</auto-claimed>\"})\n            return True\n    return False  # timeout -> shutdown\n```\n\n3. Task board scanning looks for pending, unowned, unblocked tasks.\n\n```python\ndef scan_unclaimed_tasks() -> list:\n    TASKS_DIR.mkdir(exist_ok=True)\n    unclaimed = []\n    for f in sorted(TASKS_DIR.glob(\"task_*.json\")):\n        task = json.loads(f.read_text())\n        if (task.get(\"status\") == \"pending\"\n                and not task.get(\"owner\")\n                and not task.get(\"blockedBy\")):\n            unclaimed.append(task)\n    return unclaimed\n\ndef claim_task(task_id: int, owner: str):\n    path = TASKS_DIR / f\"task_{task_id}.json\"\n    task = json.loads(path.read_text())\n    task[\"status\"] = \"in_progress\"\n    task[\"owner\"] = owner\n    path.write_text(json.dumps(task, indent=2))\n```\n\n4. Identity re-injection inserts an identity block when the context\n   is too short, indicating compression has occurred.\n\n```python\ndef make_identity_block(name, role, team_name):\n    return {\"role\": \"user\",\n            \"content\": f\"<identity>You are '{name}', \"\n                       f\"role: {role}, team: {team_name}. \"\n                       f\"Continue your work.</identity>\"}\n\n# Before resuming work after idle:\nif len(messages) <= 3:\n    messages.insert(0, make_identity_block(\n        name, role, team_name))\n    messages.insert(1, {\"role\": \"assistant\",\n        \"content\": f\"I am {name}. Continuing.\"})\n```\n\n5. The `idle` tool lets the teammate explicitly signal it has no more\n   work, entering the idle polling phase early.\n\n```python\n{\"name\": \"idle\",\n \"description\": \"Signal that you have no more work. \"\n                \"Enters idle polling phase.\",\n \"input_schema\": {\"type\": \"object\", \"properties\": {}}},\n```\n\n## Key Code\n\nThe autonomous loop (from `agents/s11_autonomous.py`):\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # WORK PHASE\n        for _ in range(50):\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            for block in response.content:\n                if block.name == \"idle\":\n                    idle_requested = True\n            if idle_requested:\n                break\n\n        # IDLE PHASE\n        self._set_status(name, \"idle\")\n        for _ in range(IDLE_TIMEOUT // POLL_INTERVAL):\n            time.sleep(POLL_INTERVAL)\n            inbox = BUS.read_inbox(name)\n            if inbox: resume = True; break\n            unclaimed = scan_unclaimed_tasks()\n            if unclaimed:\n                claim_task(unclaimed[0][\"id\"], name)\n                resume = True; break\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n## What Changed From s10\n\n| Component      | Before (s10)     | After (s11)                |\n|----------------|------------------|----------------------------|\n| Tools          | 12               | 14 (+idle, +claim_task)    |\n| Autonomy       | Lead-directed    | Self-organizing            |\n| Idle phase     | None             | Poll inbox + task board    |\n| Task claiming  | Manual only      | Auto-claim unclaimed tasks |\n| Identity       | System prompt    | + re-injection after compress|\n| Timeout        | None             | 60s idle -> auto shutdown  |\n\n## Production Reference\n\nClaude Code implements autonomous teammates with the same idle/poll/claim\ncycle. The production version uses a TaskUpdate tool for status changes\nand an idle notification system. Teammates automatically discover work\nfrom the task board and claim it without lead intervention. Identity\nre-injection ensures teammates maintain their role and context after\ncompaction. The production idle timeout is configurable per teammate.\nThe key insight: the lead creates the task board, teammates self-organize\nto complete it.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s11_autonomous.py\n```\n\nExample prompts to try:\n\n1. `Create 3 tasks on the board, then spawn alice and bob. Watch them auto-claim.`\n2. `Spawn a coder teammate and let it find work from the task board itself`\n3. `Create tasks with dependencies. Watch teammates respect the blocked order.`\n4. Type `/tasks` to see the task board with owners\n5. Type `/team` to monitor who is working vs idle\n"
  }
]